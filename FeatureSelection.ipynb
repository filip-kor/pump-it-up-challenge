{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection & Dimensionality Reduction\n",
    "Try out different feature combinations, and PCA/LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_method = \"none\"\n",
    "# Possible: \"manual\", \"none\"\n",
    "\n",
    "feature_normalisation_method = \"min-max\"\n",
    "# Possible: \"min-max\", \"z-score\", \"combined\", \"none\"\n",
    "\n",
    "dim_reduction_method = \"lda\"\n",
    "# Possible: \"pca\", \"lda\", \"none\"\n",
    "\n",
    "pca_num_components = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'status_group', 'funder', 'installer', 'latitude', 'basin',\n",
      "       'region_code', 'public_meeting', 'extraction_type',\n",
      "       'extraction_type_class', 'payment_type', 'water_quality', 'quantity',\n",
      "       'source', 'waterpoint_type', 'longitude', 'permit', 'scheme_management',\n",
      "       'gps_height', 'population', 'age', 'season', 'amount_tsh_missing',\n",
      "       'region_district', 'authority_scheme'],\n",
      "      dtype='object')\n",
      "['id', 'funder', 'installer', 'latitude', 'basin', 'region_code', 'public_meeting', 'extraction_type', 'extraction_type_class', 'payment_type', 'water_quality', 'quantity', 'source', 'waterpoint_type', 'longitude', 'permit', 'scheme_management', 'gps_height', 'population', 'age', 'season', 'amount_tsh_missing', 'region_district', 'authority_scheme']\n",
      "Numerical Cols: ['longitude', 'age', 'gps_height', 'population', 'latitude', 'id', 'public_meeting']\n"
     ]
    }
   ],
   "source": [
    "train_preprocessed_df = pd.read_csv(\"final_df.csv\")\n",
    "train_df = train_preprocessed_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "\n",
    "#test_df = pd.read_csv(\"project/data/test/test.csv\", parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "\n",
    "\n",
    "# Numerical cols\n",
    "numerical_cols = train_df.select_dtypes(include='number').columns.tolist()\n",
    "categorical_cols = ['funder','installer','basin', 'region_code', 'extraction_type', 'extraction_type_class', 'payment_type', 'water_quality',\n",
    " 'quantity', 'source', 'waterpoint_type', 'scheme_management', 'season', 'region_district', 'authority_scheme', 'population_bins', \"amount_tsh_missing\", \"permit\"]\n",
    "\n",
    "numerical_cols = list(set(numerical_cols) - set(categorical_cols))\n",
    "\n",
    "print(train_df.columns)\n",
    "\n",
    "featureList = list(train_df.columns)\n",
    "featureList.remove(\"status_group\")\n",
    "print(featureList)\n",
    "\n",
    "print(f\"Numerical Cols: {numerical_cols}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Feature Selection\n",
    "Simply use all of the processed/engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_selection_method == \"none\"):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Feature Selection\n",
    "BrendaLoznik drops these features:\n",
    "\n",
    "`'amount_tsh', 'date_recorded',  'extraction_type_group', 'lga', 'management', 'management_group', 'num_private', 'payment', 'source_class', 'source_type', 'quality_group', 'quantity_group', 'ward', 'waterpoint_type_group', 'wpt_name', 'scheme_name', 'subvillage', 'recorded_by', 'id', 'status_group'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_selection_method == \"manual\"):\n",
    "    features_to_drop = ['amount_tsh', 'date_recorded',  'extraction_type_group', 'lga', 'management', 'management_group',\n",
    "                        'num_private', 'payment', 'source_class', 'source_type', 'quality_group', 'quantity_group', 'ward',\n",
    "                        'waterpoint_type_group', 'wpt_name', 'scheme_name', 'subvillage', 'recorded_by', 'id', 'status_group']\n",
    "    train_df = train_df.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureList = list(train_df.columns)\n",
    "featureList.remove(\"status_group\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_normalisation_method == \"min-max\"):\n",
    "\n",
    "    # Create an instance of MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler to your data\n",
    "    scaler.fit(train_df[numerical_cols])\n",
    "\n",
    "    # Perform min-max scaling on your data\n",
    "    train_df[numerical_cols] = scaler.transform(train_df[numerical_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_normalisation_method == \"z-score\"):\n",
    "\n",
    "    # Create an instance of MinMaxScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler to your data\n",
    "    scaler.fit(train_df[numerical_cols])\n",
    "\n",
    "    # Perform min-max scaling on your data\n",
    "    train_df[numerical_cols] = scaler.transform(train_df[numerical_cols])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Scaling\n",
    "Manually combine Min-Max scaling, Z-score normalisation and Robust scaling on a feature-by-feature basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_normalisation_method == \"combined\"):\n",
    "\n",
    "    # Convert to normal distribution\n",
    "    zscoreColumns = [\"population\", \"gps_height\", \"age\"]\n",
    "\n",
    "    # Maintain original distribution - flatten to 0..1\n",
    "    minmaxColumns = [\"latitude\", \"longitude\"]\n",
    "\n",
    "    # Normalisation for when there's outliers\n",
    "    robustColumns = [\"population\"]\n",
    "\n",
    "\n",
    "    mmScaler = MinMaxScaler()\n",
    "    zScaler = StandardScaler()\n",
    "    rScaler = RobustScaler()\n",
    "\n",
    "    # Fit the scalers to data\n",
    "    mmScaler.fit(train_df[minmaxColumns])\n",
    "    zScaler.fit(train_df[zscoreColumns])\n",
    "    rScaler.fit(train_df[robustColumns])\n",
    "\n",
    "    # Apply scaling to each column group\n",
    "    train_df[zscoreColumns] = zScaler.transform(train_df[zscoreColumns])\n",
    "    train_df[minmaxColumns] = mmScaler.transform(train_df[minmaxColumns])\n",
    "    train_df[robustColumns] = rScaler.transform(train_df[robustColumns])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dim_reduction_method==\"pca\"):\n",
    "    # Apply PCA to all columns\n",
    "    pca = PCA(n_components=pca_num_components)\n",
    "    train_df = pca.fit_transform(train_df[featureList])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'funder', 'installer', 'latitude', 'basin', 'region_code', 'public_meeting', 'extraction_type', 'extraction_type_class', 'payment_type', 'water_quality', 'quantity', 'source', 'waterpoint_type', 'longitude', 'permit', 'scheme_management', 'gps_height', 'population', 'age', 'season', 'amount_tsh_missing', 'region_district', 'authority_scheme']\n"
     ]
    }
   ],
   "source": [
    "if(dim_reduction_method==\"lda\"):\n",
    "\n",
    "    print(featureList)\n",
    "    \n",
    "    # Create an instance of LinearDiscriminantAnalysis\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # Fit the LDA model to the scaled features and target variable\n",
    "    lda = lda.fit(train_df[featureList], train_df[\"status_group\"])\n",
    "\n",
    "    # Transform the features to the LDA space\n",
    "    train_df = lda.transform(train_df[featureList])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
