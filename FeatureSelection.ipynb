{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection & Dimensionality Reduction\n",
    "Try out different feature combinations, and PCA/LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_method = \"none\"\n",
    "# Possible: \"manual\", \"none\"\n",
    "\n",
    "feature_normalisation_method = \"min-max\"\n",
    "# Possible: \"min-max\", \"z-score\", \"combined\", \"none\"\n",
    "\n",
    "dim_reduction_method = \"lda\"\n",
    "# Possible: \"pca\", \"lda\", \"none\"\n",
    "\n",
    "pca_num_components = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Cols: ['longitude', 'age', 'gps_height', 'population', 'latitude', 'id', 'public_meeting']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamw\\AppData\\Local\\Temp\\ipykernel_14200\\2731160271.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_preprocessed_df = pd.read_csv(\"final_df.csv\")\n"
     ]
    }
   ],
   "source": [
    "train_preprocessed_df = pd.read_csv(\"final_df.csv\")\n",
    "train_df = train_preprocessed_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "\n",
    "#test_df = pd.read_csv(\"project/data/test/test.csv\", parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "\n",
    "\n",
    "# Numerical cols\n",
    "numerical_cols = train_df.select_dtypes(include='number').columns.tolist()\n",
    "categorical_cols = ['funder','installer','basin', 'region_code', 'extraction_type', 'extraction_type_class', 'payment_type', 'water_quality',\n",
    " 'quantity', 'source', 'waterpoint_type', 'scheme_management', 'season', 'region_district', 'authority_scheme', 'population_bins', \"amount_tsh_missing\", \"permit\"]\n",
    "\n",
    "numerical_cols = list(set(numerical_cols) - set(categorical_cols))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Numerical Cols: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamw\\AppData\\Local\\Temp\\ipykernel_14200\\131131981.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(\"cleaned_df.csv\")\n"
     ]
    }
   ],
   "source": [
    "temp_df = pd.read_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Continued) Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funder + Installer Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    funder     installer\n",
      "0    roman         roman\n",
      "1  grumeti       grumeti\n",
      "2    other  world vision\n",
      "3   unicef        unicef\n",
      "4    other       artisan\n"
     ]
    }
   ],
   "source": [
    "print(temp_df[[\"funder\", \"installer\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "print(temp_df[\"funder\"].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.543090\n",
       "non functional             0.384232\n",
       "functional needs repair    0.072678\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overall counts\n",
    "temp_df['status_group'].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.772277\n",
       "non functional             0.207921\n",
       "functional needs repair    0.019802\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame based on the specific value in 'column1'\n",
    "filtered_data = temp_df[temp_df['funder'] == \"germany\"]\n",
    "\n",
    "# Compute the value counts of 'column2' for the specific value in 'column1'\n",
    "filtered_data['status_group'].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                             16170\n",
       "government of tanzania            11299\n",
       "danida                             3907\n",
       "hesawa                             2782\n",
       "rwssp                              1703\n",
       "world bank                         1701\n",
       "kkkt                               1623\n",
       "world vision                       1562\n",
       "unicef                             1324\n",
       "tasaf                              1135\n",
       "dhv                                1065\n",
       "district council                   1037\n",
       "private individual                 1034\n",
       "dwsp                               1012\n",
       "norad                               949\n",
       "germany republi                     765\n",
       "water                               739\n",
       "tcrs                                735\n",
       "ministry of water                   728\n",
       "dwe                                 605\n",
       "netherlands                         592\n",
       "hifab                               577\n",
       "adb                                 551\n",
       "lga                                 546\n",
       "amref                               525\n",
       "fini water                          474\n",
       "oxfam                               436\n",
       "wateraid                            416\n",
       "rc church                           410\n",
       "rudep                               390\n",
       "isf                                 388\n",
       "private                             380\n",
       "mission                             379\n",
       "jaica                               353\n",
       "rural water supply and sanitat      338\n",
       "roman                               336\n",
       "adra                                327\n",
       "jica                                317\n",
       "ces(gmbh)                           316\n",
       "wsdp                                309\n",
       "shipo                               301\n",
       "rc                                  291\n",
       "finw                                281\n",
       "dh                                  261\n",
       "kiliwater                           243\n",
       "ded                                 237\n",
       "dmdd                                237\n",
       "plan int                            234\n",
       "lawatefuka water supply             229\n",
       "magadini-makiwaru water             226\n",
       "w.b                                 223\n",
       "oxfarm                              223\n",
       "fw                                  214\n",
       "go                                  214\n",
       "ces (gmbh)                          210\n",
       "kkkt_makwale                        209\n",
       "wvt                                 206\n",
       "oikos e.afrika                      189\n",
       "nethalan                            189\n",
       "lvia                                180\n",
       "mkinga distric coun                 180\n",
       "concern world wide                  178\n",
       "unhcr                               173\n",
       "african                             171\n",
       "no                                  163\n",
       "wananchi                            162\n",
       "ki                                  161\n",
       "swedish                             157\n",
       "community                           155\n",
       "tardo                               154\n",
       "wua                                 154\n",
       "he                                  153\n",
       "anglican church                     152\n",
       "ir                                  152\n",
       "unice                               148\n",
       "snv                                 147\n",
       "is                                  147\n",
       "roman catholic                      147\n",
       "co                                  146\n",
       "concern                             139\n",
       "tassaf                              137\n",
       "bsf                                 136\n",
       "lamp                                134\n",
       "villagers                           133\n",
       "halmashauri ya wilaya sikonge       132\n",
       "muwsa                               132\n",
       "dfid                                129\n",
       "ru                                  126\n",
       "germany                             122\n",
       "village council                     120\n",
       "hsw                                 118\n",
       "tanza                               118\n",
       "twe                                 115\n",
       "aict                                111\n",
       "idc                                 110\n",
       "mdrdp                               107\n",
       "undp                                103\n",
       "rc ch                               103\n",
       "gtz                                 102\n",
       "h                                   102\n",
       "missi                               102\n",
       "lwi                                  99\n",
       "japan                                98\n",
       "cmsr                                 98\n",
       "vwc                                  98\n",
       "ndrdp                                98\n",
       "fin water                            98\n",
       "kuwait                               98\n",
       "caritas                              97\n",
       "kibaha town council                  92\n",
       "kkkt church                          89\n",
       "cdtf                                 88\n",
       "padep                                87\n",
       "marafip                              86\n",
       "cefa                                 86\n",
       "kaemp                                83\n",
       "water aid /sema                      83\n",
       "conce                                83\n",
       "irish ai                             82\n",
       "commu                                79\n",
       "md                                   79\n",
       "national rural                       77\n",
       "mkinga  distric cou                  76\n",
       "ncaa                                 75\n",
       "losaa-kia water supply               73\n",
       "solidarm                             73\n",
       "plan international                   72\n",
       "tlc                                  71\n",
       "gen                                  71\n",
       "kilindi district co                  71\n",
       "kirde                                69\n",
       "dwe/norad                            69\n",
       "twesa                                67\n",
       "sabemo                               67\n",
       "european union                       67\n",
       "st                                   66\n",
       "ta                                   65\n",
       "wfp                                  65\n",
       "grumeti                              64\n",
       "tanapa                               64\n",
       "sema                                 63\n",
       "china government                     63\n",
       "ridep                                63\n",
       "finida german tanzania govt          62\n",
       "acra                                 61\n",
       "tabora municipal council             61\n",
       "cocen                                60\n",
       "dwssp                                59\n",
       "solidame                             58\n",
       "devon aid korogwe                    57\n",
       "tredep                               56\n",
       "Name: funder, dtype: int64"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the value counts of the column\n",
    "value_counts = temp_df['funder'].value_counts()\n",
    "\n",
    "# Identify values with fewer than X instances\n",
    "values_to_replace = value_counts[value_counts < 10].index.tolist()\n",
    "\n",
    "# Replace values with \"other\"\n",
    "temp_df['funder'] = temp_df['funder'].replace(values_to_replace, \"other\")\n",
    "temp_df[\"funder\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Feature Selection\n",
    "Simply use all of the processed/engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_selection_method == \"none\"):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Feature Selection\n",
    "BrendaLoznik drops these features:\n",
    "\n",
    "`'amount_tsh', 'date_recorded',  'extraction_type_group', 'lga', 'management', 'management_group', 'num_private', 'payment', 'source_class', 'source_type', 'quality_group', 'quantity_group', 'ward', 'waterpoint_type_group', 'wpt_name', 'scheme_name', 'subvillage', 'recorded_by', 'id', 'status_group'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_selection_method == \"manual\"):\n",
    "    features_to_drop = ['amount_tsh', 'date_recorded',  'extraction_type_group', 'lga', 'management', 'management_group',\n",
    "                        'num_private', 'payment', 'source_class', 'source_type', 'quality_group', 'quantity_group', 'ward',\n",
    "                        'waterpoint_type_group', 'wpt_name', 'scheme_name', 'subvillage', 'recorded_by', 'id', 'status_group']\n",
    "    train_df = train_df.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureList = list(train_df.columns)\n",
    "featureList.remove(\"status_group\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_normalisation_method == \"min-max\"):\n",
    "\n",
    "    # Create an instance of MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler to your data\n",
    "    scaler.fit(train_df[numerical_cols])\n",
    "\n",
    "    # Perform min-max scaling on your data\n",
    "    train_df[numerical_cols] = scaler.transform(train_df[numerical_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_normalisation_method == \"z-score\"):\n",
    "\n",
    "    # Create an instance of MinMaxScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler to your data\n",
    "    scaler.fit(train_df[numerical_cols])\n",
    "\n",
    "    # Perform min-max scaling on your data\n",
    "    train_df[numerical_cols] = scaler.transform(train_df[numerical_cols])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Scaling\n",
    "Manually combine Min-Max scaling, Z-score normalisation and Robust scaling on a feature-by-feature basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(feature_normalisation_method == \"combined\"):\n",
    "\n",
    "    # Convert to normal distribution\n",
    "    zscoreColumns = [\"population\", \"gps_height\", \"age\"]\n",
    "\n",
    "    # Maintain original distribution - flatten to 0..1\n",
    "    minmaxColumns = [\"latitude\", \"longitude\"]\n",
    "\n",
    "    # Normalisation for when there's outliers\n",
    "    robustColumns = [\"population\"]\n",
    "\n",
    "\n",
    "    mmScaler = MinMaxScaler()\n",
    "    zScaler = StandardScaler()\n",
    "    rScaler = RobustScaler()\n",
    "\n",
    "    # Fit the scalers to data\n",
    "    mmScaler.fit(train_df[minmaxColumns])\n",
    "    zScaler.fit(train_df[zscoreColumns])\n",
    "    rScaler.fit(train_df[robustColumns])\n",
    "\n",
    "    # Apply scaling to each column group\n",
    "    train_df[zscoreColumns] = zScaler.transform(train_df[zscoreColumns])\n",
    "    train_df[minmaxColumns] = mmScaler.transform(train_df[minmaxColumns])\n",
    "    train_df[robustColumns] = rScaler.transform(train_df[robustColumns])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dim_reduction_method==\"pca\"):\n",
    "    # Apply PCA to all columns\n",
    "    pca = PCA(n_components=pca_num_components)\n",
    "    reduced_df = pca.fit_transform(train_df[featureList])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14200\\4025958709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Fit the LDA model to the scaled features and target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatureList\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"status_group\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Transform the features to the LDA space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adamw\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \"\"\"\n\u001b[1;32m--> 544\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    545\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\adamw\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adamw\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adamw\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[0;32m    992\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adamw\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "if(dim_reduction_method==\"lda\"):\n",
    "\n",
    "    # Create an instance of LinearDiscriminantAnalysis\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # Fit the LDA model to the scaled features and target variable\n",
    "    lda = lda.fit(train_df[featureList], train_df[\"status_group\"])\n",
    "\n",
    "    # Transform the features to the LDA space\n",
    "    reduced_df = lda.transform(train_df[featureList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6348384  -0.11828999]\n",
      " [-0.98795118 -0.18637031]\n",
      " [-1.22236819 -0.74249202]\n",
      " ...\n",
      " [-0.14693932 -0.0160649 ]\n",
      " [-0.15982245 -0.35400913]\n",
      " [ 0.0182034  -0.43452091]]\n"
     ]
    }
   ],
   "source": [
    "print(reduced_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
