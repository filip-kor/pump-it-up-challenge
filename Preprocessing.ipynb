{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Includes imputation and deletion of bad features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: \n",
      " ['id', 'amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'region_code', 'district_code', 'population', 'construction_year']\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"project/data/train/features.csv\", parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "labels = pd.read_csv(\"project/data/train/labels.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"project/data/test/test.csv\", parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "\n",
    "# Merge features and labels files\n",
    "train_df = pd.merge(labels, train_df, on='id')\n",
    "\n",
    "print(\"Numerical columns: \\n\", train_df.select_dtypes(include=np.number).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>functional</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Mnyusi B</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ludewa</td>\n",
       "      <td>Mundindi</td>\n",
       "      <td>109.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Roman</td>\n",
       "      <td>False</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay annually</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Nyamara</td>\n",
       "      <td>Mara</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Serengeti</td>\n",
       "      <td>Natta</td>\n",
       "      <td>280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>wug</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>functional</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686.0</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Majengo</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Simanjiro</td>\n",
       "      <td>Ngorika</td>\n",
       "      <td>250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Nyumba ya mungu pipe scheme</td>\n",
       "      <td>True</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay per bucket</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>non functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263.0</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mahakamani</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>90</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kyanyamisa</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Karagwe</td>\n",
       "      <td>Nyakasimbi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group  amount_tsh date_recorded        funder  gps_height  \\\n",
       "0  69572      functional      6000.0    2011-03-14         Roman      1390.0   \n",
       "1   8776      functional         NaN    2013-03-06       Grumeti      1399.0   \n",
       "2  34310      functional        25.0    2013-02-25  Lottery Club       686.0   \n",
       "3  67743  non functional         NaN    2013-01-28        Unicef       263.0   \n",
       "4  19728      functional         NaN    2011-07-13   Action In A         NaN   \n",
       "\n",
       "      installer  longitude   latitude              wpt_name  num_private  \\\n",
       "0         Roman  34.938093  -9.856322                  none          NaN   \n",
       "1       GRUMETI  34.698766  -2.147466              Zahanati          NaN   \n",
       "2  World vision  37.460664  -3.821329           Kwa Mahundi          NaN   \n",
       "3        UNICEF  38.486161 -11.155298  Zahanati Ya Nanyumbu          NaN   \n",
       "4       Artisan  31.130847  -1.825359               Shuleni          NaN   \n",
       "\n",
       "                     basin  subvillage   region  region_code  district_code  \\\n",
       "0               Lake Nyasa    Mnyusi B   Iringa           11            5.0   \n",
       "1            Lake Victoria     Nyamara     Mara           20            2.0   \n",
       "2                  Pangani     Majengo  Manyara           21            4.0   \n",
       "3  Ruvuma / Southern Coast  Mahakamani   Mtwara           90           63.0   \n",
       "4            Lake Victoria  Kyanyamisa   Kagera           18            1.0   \n",
       "\n",
       "         lga        ward  population public_meeting              recorded_by  \\\n",
       "0     Ludewa    Mundindi       109.0           True  GeoData Consultants Ltd   \n",
       "1  Serengeti       Natta       280.0            NaN  GeoData Consultants Ltd   \n",
       "2  Simanjiro     Ngorika       250.0           True  GeoData Consultants Ltd   \n",
       "3   Nanyumbu    Nanyumbu        58.0           True  GeoData Consultants Ltd   \n",
       "4    Karagwe  Nyakasimbi         NaN           True  GeoData Consultants Ltd   \n",
       "\n",
       "  scheme_management                  scheme_name permit  construction_year  \\\n",
       "0               VWC                        Roman  False             1999.0   \n",
       "1             Other                          NaN   True             2010.0   \n",
       "2               VWC  Nyumba ya mungu pipe scheme   True             2009.0   \n",
       "3               VWC                          NaN   True             1986.0   \n",
       "4               NaN                          NaN   True                NaN   \n",
       "\n",
       "  extraction_type extraction_type_group extraction_type_class management  \\\n",
       "0         gravity               gravity               gravity        vwc   \n",
       "1         gravity               gravity               gravity        wug   \n",
       "2         gravity               gravity               gravity        vwc   \n",
       "3     submersible           submersible           submersible        vwc   \n",
       "4         gravity               gravity               gravity      other   \n",
       "\n",
       "  management_group         payment payment_type water_quality quality_group  \\\n",
       "0       user-group    pay annually     annually          soft          good   \n",
       "1       user-group       never pay    never pay          soft          good   \n",
       "2       user-group  pay per bucket   per bucket          soft          good   \n",
       "3       user-group       never pay    never pay          soft          good   \n",
       "4            other       never pay    never pay          soft          good   \n",
       "\n",
       "       quantity quantity_group                source           source_type  \\\n",
       "0        enough         enough                spring                spring   \n",
       "1  insufficient   insufficient  rainwater harvesting  rainwater harvesting   \n",
       "2        enough         enough                   dam                   dam   \n",
       "3           dry            dry           machine dbh              borehole   \n",
       "4      seasonal       seasonal  rainwater harvesting  rainwater harvesting   \n",
       "\n",
       "  source_class              waterpoint_type waterpoint_type_group  \n",
       "0  groundwater           communal standpipe    communal standpipe  \n",
       "1      surface           communal standpipe    communal standpipe  \n",
       "2      surface  communal standpipe multiple    communal standpipe  \n",
       "3  groundwater  communal standpipe multiple    communal standpipe  \n",
       "4      surface           communal standpipe    communal standpipe  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_private          98.7\n",
       "amount_tsh           70.1\n",
       "scheme_name          47.4\n",
       "population           36.0\n",
       "construction_year    34.9\n",
       "gps_height           34.4\n",
       "installer             7.5\n",
       "funder                7.4\n",
       "scheme_management     6.5\n",
       "public_meeting        5.6\n",
       "permit                5.1\n",
       "longitude             3.1\n",
       "subvillage            0.6\n",
       "payment_type          0.0\n",
       "management_group      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = round((train_df.isna().sum())/len(train_df)*100,1)\n",
    "missing = missing.sort_values(ascending = False)\n",
    "missing.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Year Imputation\n",
    "\n",
    "Since `extraction_type_group` is associated with `construction_year`, that will help to impute the values.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960.0, 2013.0, 1996.8146855857951)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#because of the wide spread of construction years, I don't want to impude by the overall mean\n",
    "train_df['construction_year'].min(),  train_df['construction_year'].max() , train_df['construction_year'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afridev</td>\n",
       "      <td>2002.316821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gravity</td>\n",
       "      <td>1995.965949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>india mark ii</td>\n",
       "      <td>2001.308428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>india mark iii</td>\n",
       "      <td>2004.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mono</td>\n",
       "      <td>1992.634541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nira/tanira</td>\n",
       "      <td>1999.421166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>other</td>\n",
       "      <td>1993.136859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>other handpump</td>\n",
       "      <td>2000.711790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>other motorpump</td>\n",
       "      <td>2011.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rope pump</td>\n",
       "      <td>2005.810256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>submersible</td>\n",
       "      <td>1999.306529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>swn 80</td>\n",
       "      <td>1996.671370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wind-powered</td>\n",
       "      <td>1995.377049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   extraction_type_group  construction_year\n",
       "0                afridev        2002.316821\n",
       "1                gravity        1995.965949\n",
       "2          india mark ii        2001.308428\n",
       "3         india mark iii        2004.126984\n",
       "4                   mono        1992.634541\n",
       "5            nira/tanira        1999.421166\n",
       "6                  other        1993.136859\n",
       "7         other handpump        2000.711790\n",
       "8        other motorpump        2011.666667\n",
       "9              rope pump        2005.810256\n",
       "10           submersible        1999.306529\n",
       "11                swn 80        1996.671370\n",
       "12          wind-powered        1995.377049"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see that the mean construction year by extraction type group gives much more detailed information\n",
    "mean_construction = train_df.groupby('extraction_type_group')['construction_year'].mean().reset_index()\n",
    "mean_construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train_df with the mean extraction year by extraction type group\n",
    "mean_construction = train_df.groupby('extraction_type_group')['construction_year'].mean().reset_index()\n",
    "mean_construction  = mean_construction .rename(columns={\"construction_year\": \"imputed_construction_year\"})\n",
    "\n",
    "#merge this train_df to the main train_df and replace missing values\n",
    "train_df = train_df.merge(mean_construction, how =  'left', on =  'extraction_type_group')\n",
    "train_df['construction_year_imputed'] = np.where(train_df['construction_year'].isna(), train_df['imputed_construction_year'], train_df['construction_year'] )\n",
    "\n",
    "#drop redundant columns\n",
    "train_df=train_df.drop(['imputed_construction_year', 'construction_year'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPS Height Imputation\n",
    "\n",
    "Replace values randomly within 1std of the mean, following a normal distribution.\n",
    "\n",
    "This probably needs verifying/improving but it'll do for now.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mean on the lowest granularity level (subvillage)\n",
    "means_altitude_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['gps_height'].mean().reset_index()#\n",
    "means_altitude_subvillage = means_altitude_subvillage.rename(columns={\"gps_height\": \"gps_height_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_altitude_ward = train_df.groupby(['region', 'lga', 'ward',])['gps_height'].mean().reset_index()\n",
    "means_altitude_ward = means_altitude_ward.rename(columns={\"gps_height\": \"gps_height_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_altitude_lga = train_df.groupby(['region', 'lga'])['gps_height'].mean().reset_index()\n",
    "means_altitude_lga = means_altitude_lga .rename(columns={\"gps_height\": \"gps_height_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_altitude_region = train_df.groupby(['region'])['gps_height'].mean().reset_index()\n",
    "means_altitude_region = means_altitude_region.rename(columns={\"gps_height\": \"gps_height_imputed_region\"})\n",
    "\n",
    "#region basin\n",
    "means_altitude_basin = train_df.groupby(['basin'])['gps_height'].mean().reset_index()\n",
    "means_altitude_basin = means_altitude_basin.rename(columns={\"gps_height\": \"gps_height_imputed_basin\"})\n",
    "\n",
    "#merge the aggregated dataframes as new columns to the original train_df\n",
    "train_df= train_df.merge(means_altitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "train_df = train_df.merge(means_altitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "train_df = train_df.merge(means_altitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "train_df = train_df.merge(means_altitude_region, how = 'left', on = ['region'])\n",
    "train_df = train_df.merge(means_altitude_basin, how = 'left', on = ['basin'])\n",
    "\n",
    "#create final imputed longitude column\n",
    "train_df['imputed_gps_height'] = np.where(train_df['gps_height'].isna(), train_df['gps_height_imputed_subvillage'], train_df['gps_height']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_ward'], train_df['imputed_gps_height']) #if subvillage mean is missing, impute it by the ward\n",
    "train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_lga'], train_df['imputed_gps_height'])\n",
    "train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_region'], train_df['imputed_gps_height'])\n",
    "train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_basin'], train_df['imputed_gps_height'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['gps_height_imputed_subvillage','gps_height_imputed_ward' , 'gps_height_imputed_lga' , 'gps_height_imputed_region', 'gps_height', 'gps_height_imputed_basin'], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude and Longitude Imputation\n",
    "0 values are replaced by subvillage, ward, lga, or region's mean logitude and latitude values for each column. \n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>longitude_imputed_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arusha</td>\n",
       "      <td>36.552713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dar es Salaam</td>\n",
       "      <td>39.215799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dodoma</td>\n",
       "      <td>36.044171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iringa</td>\n",
       "      <td>34.895989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kagera</td>\n",
       "      <td>31.233262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          region  longitude_imputed_region\n",
       "0         Arusha                 36.552713\n",
       "1  Dar es Salaam                 39.215799\n",
       "2         Dodoma                 36.044171\n",
       "3         Iringa                 34.895989\n",
       "4         Kagera                 31.233262"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['longitude'].replace(0, np.nan, inplace=True)\n",
    "#create mean longitude on the lowest granularity level (subvillage)\n",
    "means_longitude_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['longitude'].mean().reset_index()\n",
    "means_longitude_subvillage = means_longitude_subvillage.rename(columns={\"longitude\": \"longitude_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_longitude_ward = train_df.groupby(['region', 'lga', 'ward',])['longitude'].mean().reset_index()\n",
    "means_longitude_ward = means_longitude_ward.rename(columns={\"longitude\": \"longitude_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_longitude_lga = train_df.groupby(['region', 'lga'])['longitude'].mean().reset_index()\n",
    "means_longitude_lga = means_longitude_lga .rename(columns={\"longitude\": \"longitude_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_longitude_region = train_df.groupby(['region'])['longitude'].mean().reset_index()\n",
    "means_longitude_region = means_longitude_region.rename(columns={\"longitude\": \"longitude_imputed_region\"})\n",
    "means_longitude_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the aggregated dataframes as new columns to the original df\n",
    "train_df= train_df.merge(means_longitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "train_df= train_df.merge(means_longitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "train_df = train_df.merge(means_longitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "train_df = train_df.merge(means_longitude_region, how = 'left', on = ['region'])\n",
    "\n",
    "#select the right longitude level based on the availability of information\n",
    "train_df['imputed_longitude'] = np.where(train_df['longitude'].isna(), train_df['longitude_imputed_subvillage'], train_df['longitude']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_ward'], train_df['imputed_longitude']) #if subvillage mean is missing, impute it by the ward\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_lga'], train_df['imputed_longitude'])\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_region'], train_df['imputed_longitude'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['longitude_imputed_subvillage','longitude_imputed_ward' , 'longitude_imputed_lga' , 'longitude_imputed_region', 'longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>latitude_imputed_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arusha</td>\n",
       "      <td>-3.246455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dar es Salaam</td>\n",
       "      <td>-6.909677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dodoma</td>\n",
       "      <td>-5.928734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iringa</td>\n",
       "      <td>-8.907700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kagera</td>\n",
       "      <td>-1.961466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          region  latitude_imputed_region\n",
       "0         Arusha                -3.246455\n",
       "1  Dar es Salaam                -6.909677\n",
       "2         Dodoma                -5.928734\n",
       "3         Iringa                -8.907700\n",
       "4         Kagera                -1.961466"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['latitude'].where(train_df[\"latitude\"] <= -0.5, np.nan, inplace=True)\n",
    "#create mean latitude on the lowest granularity level (subvillage)\n",
    "means_latitude_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['latitude'].mean().reset_index()\n",
    "means_latitude_subvillage = means_latitude_subvillage.rename(columns={\"latitude\": \"latitude_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_latitude_ward = train_df.groupby(['region', 'lga', 'ward',])['latitude'].mean().reset_index()\n",
    "means_latitude_ward = means_latitude_ward.rename(columns={\"latitude\": \"latitude_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_latitude_lga = train_df.groupby(['region', 'lga'])['latitude'].mean().reset_index()\n",
    "means_latitude_lga = means_latitude_lga .rename(columns={\"latitude\": \"latitude_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_latitude_region = train_df.groupby(['region'])['latitude'].mean().reset_index()\n",
    "means_latitude_region = means_latitude_region.rename(columns={\"latitude\": \"latitude_imputed_region\"})\n",
    "means_latitude_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the aggregated dataframes as new columns to the original df\n",
    "train_df= train_df.merge(means_latitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "train_df= train_df.merge(means_latitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "train_df = train_df.merge(means_latitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "train_df = train_df.merge(means_latitude_region, how = 'left', on = ['region'])\n",
    "\n",
    "#select the right latitude level based on the availability of information\n",
    "train_df['imputed_latitude'] = np.where(train_df['latitude'].isna(), train_df['latitude_imputed_subvillage'], train_df['latitude']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "train_df['imputed_latitude'] = np.where(train_df['imputed_latitude'].isna(), train_df['latitude_imputed_ward'], train_df['imputed_latitude']) #if subvillage mean is missing, impute it by the ward\n",
    "train_df['imputed_latitude'] = np.where(train_df['imputed_latitude'].isna(), train_df['latitude_imputed_lga'], train_df['imputed_latitude'])\n",
    "train_df['imputed_latitude'] = np.where(train_df['imputed_latitude'].isna(), train_df['latitude_imputed_region'], train_df['imputed_latitude'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['latitude_imputed_subvillage','latitude_imputed_ward' , 'latitude_imputed_lga' , 'latitude_imputed_region', 'latitude'], axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permit Imputation\n",
    "Impute missing values with mode of similar records. `management_group` and `public_meeting` were used by BrendaLoznik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute by mode\n",
    "permit_mg_mode= train_df.groupby(['public_meeting', 'management_group'])['permit'].agg(pd.Series.mode).reset_index()\n",
    "permit_mg_mode  = permit_mg_mode.rename(columns={\"permit\": \"imputed_permit_mg\"})\n",
    "train_df = train_df.merge(permit_mg_mode, how = 'left', on = ['public_meeting', 'management_group'])\n",
    "\n",
    "train_df['imputed_permit'] = np.where(train_df['permit'].isna(), train_df['imputed_permit_mg'], train_df['permit'])  #if permit is missing, replace it by the mode of public meeting - management group\n",
    "train_df['imputed_permit']  = np.where(train_df['imputed_permit'] .isna(), train_df['permit'].mode(), train_df['imputed_permit'])  #if eitther public meeting or management group is missing, then use the mode of permit (True)\n",
    "\n",
    "#drop original permit column\n",
    "train_df = train_df.drop(['permit', 'imputed_permit_mg'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Meeting Imputation\n",
    "Simply impute public_meeting with the mode, as 90% of pumps have a TRUE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_meeting_mode = train_df['public_meeting'].mode()[0]\n",
    "train_df['public_meeting'] = train_df['public_meeting'].fillna(public_meeting_mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheme Management Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12344\\1693945358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#merge scheme_mode to original df and use it to replace missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheme_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;34m'management'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'imputed_scheme__management'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scheme_management'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'imputed_scheme_management'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scheme_management'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#drop redundant columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw' is not defined"
     ]
    }
   ],
   "source": [
    "# it seems like a logical choice to impute missing scheme management values by the mode of the management - scheme-management as there is a lot of overlap here\n",
    "check = train_df.groupby([  'management_group', 'scheme_management' , 'management'])['id'].count().reset_index()\n",
    "check = check.sort_values('management')\n",
    "check.head(10)\n",
    "\n",
    "scheme_mode = train_df.groupby(['management'])['scheme_management'].agg(pd.Series.mode).reset_index()\n",
    "scheme_mode = scheme_mode.rename(columns={\"scheme_management\": \"imputed_scheme_management\"})\n",
    "scheme_mode \n",
    "\n",
    "#merge scheme_mode to original df and use it to replace missing values\n",
    "train_df = train_df.merge(scheme_mode, how = 'left', on = [ 'management'])\n",
    "raw['imputed_scheme__management'] = np.where(raw['scheme_management'].isna(), raw['imputed_scheme_management'], raw['scheme_management'])\n",
    "\n",
    "#drop redundant columns\n",
    "raw= raw.drop(['scheme_management', 'imputed_scheme_management'],axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed a lot of variation in captialization, so I will first convert al entries to lowercase\n",
    "raw['installer'] = raw['installer'].str.lower()\n",
    "\n",
    "#plot top 10 installers\n",
    "installer = raw.groupby('installer')['id'].count().reset_index()\n",
    "installer = installer.sort_values('id', ascending = False)\n",
    "installer.head(10)\n",
    "\n",
    "\n",
    "#there are a few categories in the top 60 most common categories whose naims look a lot alike and are probably typo's. We will merge them together\n",
    "raw['installer'] = np.where( raw['installer']=='gove', 'gover', raw['installer'] )\n",
    "raw['installer'] = np.where( raw['installer']=='community', 'commu', raw['installer'] )\n",
    "raw['installer'] = np.where( raw['installer']=='danid', 'danida', raw['installer'] )\n",
    "\n",
    "installer = raw.groupby('installer')['id'].count().reset_index()\n",
    "installer = installer.sort_values('id', ascending = False)\n",
    "installer.head(10)\n",
    "\n",
    "#I want to keep the most frequent installers and combine the rarer classes together. I have played around with the optimum number of installers to keep, and I decided on the top 150.\n",
    "\n",
    "#create list of top 150 installers\n",
    "top_installers = installer.nlargest(150, 'id')['installer'].unique()\n",
    "\n",
    "#replace funders that are not in top 10 with 'other'\n",
    "raw['installer'] = np.where(raw['installer'].isin(top_installers), raw['installer'], 'other')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set all entries to lowercase\n",
    "train_df['funder'] = raw['funder'].str.lower()\n",
    "\n",
    "\n",
    "funder = train_df.groupby('funder')['id'].count().reset_index()\n",
    "funder = funder.sort_values('id', ascending = False)\n",
    "funder.head(10)\n",
    "\n",
    "#create list of top 150 funders\n",
    "top_funders = funder.nlargest(150, 'id')['funder'].unique()\n",
    "\n",
    "#replace funders that are not in top 150 with 'other'\n",
    "train_df['funder'] = np.where(train_df['funder'].isin(top_funders), train_df['funder'], 'other')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population\n",
    "Brenda's solution considers region-wide population average when not available, which is a poor indicator of population. Some readings also have very large population values, which skew the average. We use a binning approach to better represent population, with a \"missing\" bin where subvillage or ward population is unknown, as this itself is a decent predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12344\\2688446765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Print distribution of population\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;34m'population'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#66c2a5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Population distribution'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recorded_age Feature\n",
    "Create a feature recorded_age, which states the age (in years) of the pump at time of recording. Uses date_recorded and construction_year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['recorded_year'] = pd.DatetimeIndex(train_df['date_recorded']).year\n",
    "train_df['recorded_age'] = train_df['recorded_year'] - train_df['construction_year']\n",
    "train_df = train_df.drop('recorded_year',axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (Partial) Feature Selection\n",
    "Remove bad features here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns to Drop\n",
    "amount_tsh: *70% missing values*\n",
    "\n",
    "date_recorded: *Used in recorded_age engineered feature*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"date_recorded\", \"scheme_name\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
