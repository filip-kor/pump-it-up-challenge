{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Includes imputation and deletion of bad features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: \n",
      " ['id', 'amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'region_code', 'district_code', 'population', 'construction_year']\n"
     ]
    }
   ],
   "source": [
    "train_base_df = pd.read_csv(\"project/data/train/features.csv\", parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "labels = pd.read_csv(\"project/data/train/labels.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"project/data/test/test.csv\", parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "\n",
    "# Merge features and labels files\n",
    "train_df = pd.merge(labels, train_base_df, on='id')\n",
    "\n",
    "print(\"Numerical columns: \\n\", train_df.select_dtypes(include=np.number).columns.tolist())\n",
    "\n",
    "# Introducing: DATA LEAKAGE\n",
    "train_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>functional</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Mnyusi B</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ludewa</td>\n",
       "      <td>Mundindi</td>\n",
       "      <td>109.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Roman</td>\n",
       "      <td>False</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay annually</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Nyamara</td>\n",
       "      <td>Mara</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Serengeti</td>\n",
       "      <td>Natta</td>\n",
       "      <td>280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>wug</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>functional</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686.0</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Majengo</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Simanjiro</td>\n",
       "      <td>Ngorika</td>\n",
       "      <td>250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Nyumba ya mungu pipe scheme</td>\n",
       "      <td>True</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay per bucket</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>non functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263.0</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mahakamani</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>90</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kyanyamisa</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Karagwe</td>\n",
       "      <td>Nyakasimbi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group  amount_tsh date_recorded        funder  gps_height  \\\n",
       "0  69572      functional      6000.0    2011-03-14         Roman      1390.0   \n",
       "1   8776      functional         NaN    2013-03-06       Grumeti      1399.0   \n",
       "2  34310      functional        25.0    2013-02-25  Lottery Club       686.0   \n",
       "3  67743  non functional         NaN    2013-01-28        Unicef       263.0   \n",
       "4  19728      functional         NaN    2011-07-13   Action In A         NaN   \n",
       "\n",
       "      installer  longitude   latitude              wpt_name  num_private  \\\n",
       "0         Roman  34.938093  -9.856322                  none          NaN   \n",
       "1       GRUMETI  34.698766  -2.147466              Zahanati          NaN   \n",
       "2  World vision  37.460664  -3.821329           Kwa Mahundi          NaN   \n",
       "3        UNICEF  38.486161 -11.155298  Zahanati Ya Nanyumbu          NaN   \n",
       "4       Artisan  31.130847  -1.825359               Shuleni          NaN   \n",
       "\n",
       "                     basin  subvillage   region  region_code  district_code  \\\n",
       "0               Lake Nyasa    Mnyusi B   Iringa           11            5.0   \n",
       "1            Lake Victoria     Nyamara     Mara           20            2.0   \n",
       "2                  Pangani     Majengo  Manyara           21            4.0   \n",
       "3  Ruvuma / Southern Coast  Mahakamani   Mtwara           90           63.0   \n",
       "4            Lake Victoria  Kyanyamisa   Kagera           18            1.0   \n",
       "\n",
       "         lga        ward  population public_meeting              recorded_by  \\\n",
       "0     Ludewa    Mundindi       109.0           True  GeoData Consultants Ltd   \n",
       "1  Serengeti       Natta       280.0            NaN  GeoData Consultants Ltd   \n",
       "2  Simanjiro     Ngorika       250.0           True  GeoData Consultants Ltd   \n",
       "3   Nanyumbu    Nanyumbu        58.0           True  GeoData Consultants Ltd   \n",
       "4    Karagwe  Nyakasimbi         NaN           True  GeoData Consultants Ltd   \n",
       "\n",
       "  scheme_management                  scheme_name permit  construction_year  \\\n",
       "0               VWC                        Roman  False             1999.0   \n",
       "1             Other                          NaN   True             2010.0   \n",
       "2               VWC  Nyumba ya mungu pipe scheme   True             2009.0   \n",
       "3               VWC                          NaN   True             1986.0   \n",
       "4               NaN                          NaN   True                NaN   \n",
       "\n",
       "  extraction_type extraction_type_group extraction_type_class management  \\\n",
       "0         gravity               gravity               gravity        vwc   \n",
       "1         gravity               gravity               gravity        wug   \n",
       "2         gravity               gravity               gravity        vwc   \n",
       "3     submersible           submersible           submersible        vwc   \n",
       "4         gravity               gravity               gravity      other   \n",
       "\n",
       "  management_group         payment payment_type water_quality quality_group  \\\n",
       "0       user-group    pay annually     annually          soft          good   \n",
       "1       user-group       never pay    never pay          soft          good   \n",
       "2       user-group  pay per bucket   per bucket          soft          good   \n",
       "3       user-group       never pay    never pay          soft          good   \n",
       "4            other       never pay    never pay          soft          good   \n",
       "\n",
       "       quantity quantity_group                source           source_type  \\\n",
       "0        enough         enough                spring                spring   \n",
       "1  insufficient   insufficient  rainwater harvesting  rainwater harvesting   \n",
       "2        enough         enough                   dam                   dam   \n",
       "3           dry            dry           machine dbh              borehole   \n",
       "4      seasonal       seasonal  rainwater harvesting  rainwater harvesting   \n",
       "\n",
       "  source_class              waterpoint_type waterpoint_type_group  \n",
       "0  groundwater           communal standpipe    communal standpipe  \n",
       "1      surface           communal standpipe    communal standpipe  \n",
       "2      surface  communal standpipe multiple    communal standpipe  \n",
       "3  groundwater  communal standpipe multiple    communal standpipe  \n",
       "4      surface           communal standpipe    communal standpipe  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_private          98.7\n",
       "amount_tsh           70.1\n",
       "scheme_name          47.5\n",
       "population           36.1\n",
       "construction_year    35.0\n",
       "gps_height           34.5\n",
       "status_group         20.0\n",
       "installer             7.4\n",
       "funder                7.4\n",
       "scheme_management     6.5\n",
       "public_meeting        5.6\n",
       "permit                5.1\n",
       "longitude             3.1\n",
       "subvillage            0.6\n",
       "payment_type          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = round((train_df.isna().sum())/len(train_df)*100,1)\n",
    "missing = missing.sort_values(ascending = False)\n",
    "missing.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude and Longitude Imputation\n",
    "0 values are replaced by subvillage, ward, lga, or region's mean logitude and latitude values for each column. \n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>longitude_imputed_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arusha</td>\n",
       "      <td>36.554067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dar es Salaam</td>\n",
       "      <td>39.212935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dodoma</td>\n",
       "      <td>36.041964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iringa</td>\n",
       "      <td>34.895921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kagera</td>\n",
       "      <td>31.233092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          region  longitude_imputed_region\n",
       "0         Arusha                 36.554067\n",
       "1  Dar es Salaam                 39.212935\n",
       "2         Dodoma                 36.041964\n",
       "3         Iringa                 34.895921\n",
       "4         Kagera                 31.233092"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df['longitude'].replace(0, np.nan, inplace=True)\n",
    "#create mean longitude on the lowest granularity level (subvillage)\n",
    "means_longitude_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['longitude'].mean().reset_index()\n",
    "means_longitude_subvillage = means_longitude_subvillage.rename(columns={\"longitude\": \"longitude_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_longitude_ward = train_df.groupby(['region', 'lga', 'ward',])['longitude'].mean().reset_index()\n",
    "means_longitude_ward = means_longitude_ward.rename(columns={\"longitude\": \"longitude_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_longitude_lga = train_df.groupby(['region', 'lga'])['longitude'].mean().reset_index()\n",
    "means_longitude_lga = means_longitude_lga .rename(columns={\"longitude\": \"longitude_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_longitude_region = train_df.groupby(['region'])['longitude'].mean().reset_index()\n",
    "means_longitude_region = means_longitude_region.rename(columns={\"longitude\": \"longitude_imputed_region\"})\n",
    "means_longitude_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the aggregated dataframes as new columns to the original df\n",
    "train_df= train_df.merge(means_longitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "train_df= train_df.merge(means_longitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "train_df = train_df.merge(means_longitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "train_df = train_df.merge(means_longitude_region, how = 'left', on = ['region'])\n",
    "\n",
    "#select the right longitude level based on the availability of information\n",
    "train_df['imputed_longitude'] = np.where(train_df['longitude'].isna(), train_df['longitude_imputed_subvillage'], train_df['longitude']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_ward'], train_df['imputed_longitude']) #if subvillage mean is missing, impute it by the ward\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_lga'], train_df['imputed_longitude'])\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_region'], train_df['imputed_longitude'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['longitude_imputed_subvillage','longitude_imputed_ward' , 'longitude_imputed_lga' , 'longitude_imputed_region', 'longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['latitude'].where(train_df[\"latitude\"] <= -0.5, np.nan, inplace=True)\n",
    "# #create mean latitude on the lowest granularity level (subvillage)\n",
    "# means_latitude_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['latitude'].mean().reset_index()\n",
    "# means_latitude_subvillage = means_latitude_subvillage.rename(columns={\"latitude\": \"latitude_imputed_subvillage\"})\n",
    "\n",
    "# #ward level\n",
    "# means_latitude_ward = train_df.groupby(['region', 'lga', 'ward',])['latitude'].mean().reset_index()\n",
    "# means_latitude_ward = means_latitude_ward.rename(columns={\"latitude\": \"latitude_imputed_ward\"})\n",
    "\n",
    "# #lga level\n",
    "# means_latitude_lga = train_df.groupby(['region', 'lga'])['latitude'].mean().reset_index()\n",
    "# means_latitude_lga = means_latitude_lga .rename(columns={\"latitude\": \"latitude_imputed_lga\"})\n",
    "\n",
    "# #region level\n",
    "# means_latitude_region = train_df.groupby(['region'])['latitude'].mean().reset_index()\n",
    "# means_latitude_region = means_latitude_region.rename(columns={\"latitude\": \"latitude_imputed_region\"})\n",
    "# means_latitude_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #merge the aggregated dataframes as new columns to the original df\n",
    "# train_df= train_df.merge(means_latitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "# train_df= train_df.merge(means_latitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "# train_df = train_df.merge(means_latitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "# train_df = train_df.merge(means_latitude_region, how = 'left', on = ['region'])\n",
    "\n",
    "# #select the right latitude level based on the availability of information\n",
    "# train_df['imputed_latitude'] = np.where(train_df['latitude'].isna(), train_df['latitude_imputed_subvillage'], train_df['latitude']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "# train_df['imputed_latitude'] = np.where(train_df['imputed_latitude'].isna(), train_df['latitude_imputed_ward'], train_df['imputed_latitude']) #if subvillage mean is missing, impute it by the ward\n",
    "# train_df['imputed_latitude'] = np.where(train_df['imputed_latitude'].isna(), train_df['latitude_imputed_lga'], train_df['imputed_latitude'])\n",
    "# train_df['imputed_latitude'] = np.where(train_df['imputed_latitude'].isna(), train_df['latitude_imputed_region'], train_df['imputed_latitude'])\n",
    "\n",
    "# #drop redundant columns\n",
    "# train_df= train_df.drop(['latitude_imputed_subvillage','latitude_imputed_ward' , 'latitude_imputed_lga' , 'latitude_imputed_region', 'latitude'], axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permit Imputation\n",
    "Impute missing values with mode of similar records. `management_group` and `public_meeting` were used by BrendaLoznik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute by mode\n",
    "permit_mg_mode= train_df.groupby(['public_meeting', 'management_group'])['permit'].agg(pd.Series.mode).reset_index()\n",
    "permit_mg_mode  = permit_mg_mode.rename(columns={\"permit\": \"imputed_permit_mg\"})\n",
    "train_df = train_df.merge(permit_mg_mode, how = 'left', on = ['public_meeting', 'management_group'])\n",
    "\n",
    "train_df['imputed_permit'] = np.where(train_df['permit'].isna(), train_df['imputed_permit_mg'], train_df['permit'])  #if permit is missing, replace it by the mode of public meeting - management group\n",
    "train_df['imputed_permit']  = np.where(train_df['imputed_permit'] .isna(), train_df['permit'].mode(), train_df['imputed_permit'])  #if eitther public meeting or management group is missing, then use the mode of permit (True)\n",
    "\n",
    "#drop original permit column\n",
    "train_df = train_df.drop(['permit', 'imputed_permit_mg'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Meeting Imputation\n",
    "Simply impute public_meeting with the mode, as 90% of pumps have a TRUE value\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_meeting_mode = train_df['public_meeting'].mode()[0]\n",
    "train_df['public_meeting'] = train_df['public_meeting'].fillna(public_meeting_mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheme Management Imputation\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems like a logical choice to impute missing scheme management values by the mode of the management - scheme-management as there is a lot of overlap here\n",
    "check = train_df.groupby([  'management_group', 'scheme_management' , 'management'])['id'].count().reset_index()\n",
    "check = check.sort_values('management')\n",
    "check.head(10)\n",
    "\n",
    "scheme_mode = train_df.groupby(['management'])['scheme_management'].agg(pd.Series.mode).reset_index()\n",
    "scheme_mode = scheme_mode.rename(columns={\"scheme_management\": \"imputed_scheme_management\"})\n",
    "scheme_mode \n",
    "\n",
    "#merge scheme_mode to original df and use it to replace missing values\n",
    "train_df = train_df.merge(scheme_mode, how = 'left', on = [ 'management'])\n",
    "train_df['imputed_scheme__management'] = np.where(train_df['scheme_management'].isna(), train_df['imputed_scheme_management'], train_df['scheme_management'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['scheme_management', 'imputed_scheme_management'],axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installer\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed a lot of variation in captialization, so I will first convert al entries to lowercase\n",
    "train_df['installer'] = train_df['installer'].str.lower()\n",
    "\n",
    "#plot top 10 installers\n",
    "installer = train_df.groupby('installer')['id'].count().reset_index()\n",
    "installer = installer.sort_values('id', ascending = False)\n",
    "installer.head(10)\n",
    "\n",
    "\n",
    "#there are a few categories in the top 60 most common categories whose naims look a lot alike and are probably typo's. We will merge them together\n",
    "train_df['installer'] = np.where( train_df['installer']=='gove', 'gover', train_df['installer'] )\n",
    "train_df['installer'] = np.where( train_df['installer']=='community', 'commu', train_df['installer'] )\n",
    "train_df['installer'] = np.where( train_df['installer']=='danid', 'danida', train_df['installer'] )\n",
    "\n",
    "installer = train_df.groupby('installer')['id'].count().reset_index()\n",
    "installer = installer.sort_values('id', ascending = False)\n",
    "installer.head(10)\n",
    "\n",
    "#I want to keep the most frequent installers and combine the rarer classes together. I have played around with the optimum number of installers to keep, and I decided on the top 150.\n",
    "\n",
    "#create list of top 150 installers\n",
    "top_installers = installer.nlargest(150, 'id')['installer'].unique()\n",
    "\n",
    "#replace funders that are not in top 10 with 'other'\n",
    "train_df['installer'] = np.where(train_df['installer'].isin(top_installers), train_df['installer'], 'other')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funder\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set all entries to lowercase\n",
    "train_df['funder'] = train_df['funder'].str.lower()\n",
    "\n",
    "\n",
    "funder = train_df.groupby('funder')['id'].count().reset_index()\n",
    "funder = funder.sort_values('id', ascending = False)\n",
    "funder.head(10)\n",
    "\n",
    "#create list of top 150 funders\n",
    "top_funders = funder.nlargest(150, 'id')['funder'].unique()\n",
    "\n",
    "#replace funders that are not in top 150 with 'other'\n",
    "train_df['funder'] = np.where(train_df['funder'].isin(top_funders), train_df['funder'], 'other')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Year Imputation\n",
    "\n",
    "Since `extraction_type_group` is associated with `construction_year`, that will help to impute the values.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because of the wide spread of construction years, I don't want to impude by the overall mean\n",
    "train_df['construction_year'].min(),  train_df['construction_year'].max() , train_df['construction_year'].mean()\n",
    "\n",
    "#We can see that the mean construction year by extraction type group gives much more detailed information\n",
    "mean_construction = train_df.groupby('extraction_type_group')['construction_year'].mean().reset_index()\n",
    "\n",
    "#create train_df with the mean extraction year by extraction type group\n",
    "mean_construction = train_df.groupby('extraction_type_group')['construction_year'].mean().reset_index()\n",
    "mean_construction  = mean_construction .rename(columns={\"construction_year\": \"imputed_construction_year\"})\n",
    "\n",
    "#merge this train_df to the main train_df and replace missing values\n",
    "train_df = train_df.merge(mean_construction, how =  'left', on =  'extraction_type_group')\n",
    "train_df['construction_year_imputed'] = np.where(train_df['construction_year'].isna(), train_df['imputed_construction_year'], train_df['construction_year'] )\n",
    "\n",
    "#drop redundant columns\n",
    "train_df=train_df.drop(['imputed_construction_year', 'construction_year'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPS Height Imputation\n",
    "\n",
    "Replace values randomly within 1std of the mean, following a normal distribution.\n",
    "\n",
    "This probably needs verifying/improving but it'll do for now.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mean on the lowest granularity level (subvillage)\n",
    "means_altitude_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['gps_height'].mean().reset_index()#\n",
    "means_altitude_subvillage = means_altitude_subvillage.rename(columns={\"gps_height\": \"gps_height_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_altitude_ward = train_df.groupby(['region', 'lga', 'ward',])['gps_height'].mean().reset_index()\n",
    "means_altitude_ward = means_altitude_ward.rename(columns={\"gps_height\": \"gps_height_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_altitude_lga = train_df.groupby(['region', 'lga'])['gps_height'].mean().reset_index()\n",
    "means_altitude_lga = means_altitude_lga .rename(columns={\"gps_height\": \"gps_height_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_altitude_region = train_df.groupby(['region'])['gps_height'].mean().reset_index()\n",
    "means_altitude_region = means_altitude_region.rename(columns={\"gps_height\": \"gps_height_imputed_region\"})\n",
    "\n",
    "#region basin\n",
    "means_altitude_basin = train_df.groupby(['basin'])['gps_height'].mean().reset_index()\n",
    "means_altitude_basin = means_altitude_basin.rename(columns={\"gps_height\": \"gps_height_imputed_basin\"})\n",
    "\n",
    "#merge the aggregated dataframes as new columns to the original train_df\n",
    "train_df= train_df.merge(means_altitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "train_df = train_df.merge(means_altitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "train_df = train_df.merge(means_altitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "train_df = train_df.merge(means_altitude_region, how = 'left', on = ['region'])\n",
    "train_df = train_df.merge(means_altitude_basin, how = 'left', on = ['basin'])\n",
    "\n",
    "#create final imputed longitude column\n",
    "train_df['imputed_gps_height'] = np.where(train_df['gps_height'].isna(), train_df['gps_height_imputed_subvillage'], train_df['gps_height']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_ward'], train_df['imputed_gps_height']) #if subvillage mean is missing, impute it by the ward\n",
    "train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_lga'], train_df['imputed_gps_height'])\n",
    "train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_region'], train_df['imputed_gps_height'])\n",
    "train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_basin'], train_df['imputed_gps_height'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['gps_height_imputed_subvillage','gps_height_imputed_ward' , 'gps_height_imputed_lga' , 'gps_height_imputed_region', 'gps_height', 'gps_height_imputed_basin'], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population\n",
    "Brenda's solution considers region-wide population average when not available, which is a poor indicator of population. Some readings also have very large population values, which skew the average. We use a binning approach to better represent population, with a \"missing\" bin where subvillage or ward population is unknown, as this itself is a decent predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mean on the lowest granularity level (subvillage)\n",
    "means_population_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['population'].mean().reset_index()#\n",
    "means_population_subvillage = means_population_subvillage.rename(columns={\"population\": \"population_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_population_ward = train_df.groupby(['region', 'lga', 'ward',])['population'].mean().reset_index()\n",
    "means_population_ward = means_population_ward.rename(columns={\"population\": \"population_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_population_lga = train_df.groupby(['region', 'lga'])['population'].mean().reset_index()\n",
    "means_population_lga = means_population_lga .rename(columns={\"population\": \"population_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_population_region = train_df.groupby(['region'])['population'].mean().reset_index()\n",
    "means_population_region = means_population_region.rename(columns={\"population\": \"population_imputed_region\"})\n",
    "\n",
    "#region basin\n",
    "means_population_basin = train_df.groupby(['basin'])['population'].mean().reset_index()\n",
    "means_population_basin = means_population_basin.rename(columns={\"population\": \"population_imputed_basin\"})\n",
    "\n",
    "#merge the aggregated dataframes as new columns to the original df\n",
    "train_df= train_df.merge(means_population_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "train_df = train_df.merge(means_population_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "train_df = train_df.merge(means_population_lga, how = 'left', on = ['region', 'lga'])\n",
    "train_df = train_df.merge(means_population_region, how = 'left', on = ['region'])\n",
    "train_df = train_df.merge(means_population_basin, how = 'left', on = ['basin'])\n",
    "\n",
    "#create final imputed longitude column\n",
    "train_df['imputed_population'] = np.where(train_df['population'].isna(), train_df['population_imputed_subvillage'], train_df['population']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "train_df['imputed_population'] = np.where(train_df['imputed_population'].isna(), train_df['population_imputed_ward'], train_df['imputed_population']) #if subvillage mean is missing, impute it by the ward\n",
    "train_df['imputed_population'] = np.where(train_df['imputed_population'].isna(), train_df['population_imputed_lga'], train_df['imputed_population'])\n",
    "train_df['imputed_population'] = np.where(train_df['imputed_population'].isna(), train_df['population_imputed_region'], train_df['imputed_population'])\n",
    "train_df['imputed_population'] = np.where(train_df['imputed_population'].isna(), train_df['population_imputed_basin'], train_df['imputed_population'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['population_imputed_subvillage','population_imputed_ward' , 'population_imputed_lga' , 'population_imputed_region', 'population', 'population_imputed_basin'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace string to integer\n",
    "train_df['public_meeting'] = train_df['public_meeting'].replace({True: 1, False: 0})\n",
    "train_df['imputed_permit'] = train_df['imputed_permit'].replace({True: 1, False: 0})\n",
    "\n",
    "\n",
    "#change to integer\n",
    "train_df[['imputed_gps_height', 'construction_year_imputed', 'imputed_population']] = train_df[['imputed_gps_height', 'construction_year_imputed', 'imputed_population']].astype('int')\n",
    "\n",
    "#change type to categorical\n",
    "train_df[['region_code', 'district_code', 'num_private']] = train_df[['region_code', 'district_code', 'num_private']].astype('str')\n",
    "train_df[[ 'num_private']] = train_df[[ 'num_private']].astype('str')\n",
    "\n",
    "#remove decimal\n",
    "train_df['district_code'] = train_df['district_code'].str.split(\".\").str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned df\n",
    "train_df= train_df.rename(columns={\"imputed_permit\": \"permit\", \"imputed_scheme__management\": \"scheme_management\",\n",
    "                    \"imputed_gps_height\": \"gps_height\", 'construction_year_imputed': 'construction_year', \n",
    "                   'imputed_population': 'population', 'imputed_longitude': 'longitude'}, errors=\"raise\")\n",
    "# , 'imputed_latitude': 'latitude'\n",
    "\n",
    "train_df.to_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recorded_age Feature\n",
    "Create a feature recorded_age, which states the age (in years) of the pump at time of recording. Uses date_recorded and construction_year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create age feature\n",
    "train_df['recorded_year'] = pd.DatetimeIndex(train_df ['date_recorded']).year\n",
    "train_df[ 'age'] = train_df['recorded_year'] - train_df['construction_year']\n",
    "train_df = train_df.drop('recorded_year',axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorded Season\n",
    "The month in which the water pump's functionality is recorded may be important due to wet/dry seasons in Tanzania. Due to the poor distribution of recorded months, we group months into different season bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['month'] = pd.DatetimeIndex(train_df['date_recorded']).month\n",
    "\n",
    "# season encoder\n",
    "season_mapper = {1: 'short dry',2:'short dry', 3: 'long rain', 4: 'long rain', 5: 'long rain',6: 'long dry', \n",
    "                 7: 'long dry', 8: 'long dry', 9: 'long dry', 10: 'long dry', 11:'short rain', 12:'short rain'}\n",
    "#.p feature values to scale\n",
    "train_df['season'] = train_df['month'].replace(season_mapper)\n",
    "train_df = train_df.drop('month', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### amount_tsh missing\n",
    "Use a binary feature for whether amount_tsh is missing - this is a decent predictor of water pump status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['amount_tsh_missing'] = np.where( train_df['amount_tsh'].isna(), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['region_district'] = train_df['region']+ \"-\" + train_df['district_code']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Cardinality of Longitude/Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two decimal places is 1.1 km accurate. This will provide enough information on the location. Using the full coordinate doesn't provide a lot of general information, but does result in high cardinality\n",
    "train_df['longitude'] = round(train_df['longitude'], 2)\n",
    "train_df['latitude'] = round(train_df['latitude'],2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i want to keep extraction type class and I will group the extraction type group en type together\n",
    "\n",
    "#swn 80 and swn 81 become swn\n",
    "#cemo + climax become other motorpump\n",
    "# other -mkulima, other -play and walimi become other handpump\n",
    "\n",
    "swn = ['other - swn 81', 'swn80']\n",
    "train_df['extraction_type'] =np.where(train_df['extraction_type'].isin(swn), 'swn',  train_df['extraction_type'])\n",
    "\n",
    "other_handpump = ['other - mkulima/shinyanga', 'other - play pump', 'other - walimi']\n",
    "train_df['extraction_type']=np.where(train_df['extraction_type'].isin(other_handpump), 'other handpump',  train_df['extraction_type'])\n",
    "\n",
    "other_motorpump = ['cemo', 'climax']\n",
    "train_df['extraction_type'] =np.where(train_df['extraction_type'].isin(other_motorpump), 'other motorpump',  train_df['extraction_type'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autonomous = government, VWC, town council ..... also water authority?, parastatal (=state company)? SWC?\n",
    "#autonomous = WUA, WUG, board, trust, school\n",
    "#private = private, company\n",
    "\n",
    "non = ['VWC', 'Water authority', 'Parastatal', 'SWC']\n",
    "autonomous = ['WUG', 'WUA', 'Water Board', 'Trust']\n",
    "private = ['Company', 'Private operator']\n",
    "other = ['None', 'Other']\n",
    "\n",
    "train_df['authority_scheme'] = train_df['scheme_management']\n",
    "train_df.loc[train_df['authority_scheme'].isin(non),'authority_scheme']='non-autonomous'\n",
    "train_df.loc[train_df['authority_scheme'].isin(autonomous ),'authority_scheme']='autonomous'\n",
    "train_df.loc[train_df['authority_scheme'].isin(private),'authority_scheme']='private'\n",
    "train_df.loc[train_df['authority_scheme'].isin(other ),'authority_scheme']='other'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine rare features in `source`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep source, but the rare classes will be put together\n",
    "other = ['other',  'unknown']\n",
    "train_df['source'] = np.where(train_df['source']=='unknown', 'other', train_df['source'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (Partial) Feature Selection\n",
    "Remove bad features here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns to Drop\n",
    "amount_tsh: *70% missing values*\n",
    "\n",
    "date_recorded: *Used in recorded_age engineered feature*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "      <th>funder</th>\n",
       "      <th>installer</th>\n",
       "      <th>latitude</th>\n",
       "      <th>basin</th>\n",
       "      <th>region_code</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>longitude</th>\n",
       "      <th>permit</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>population</th>\n",
       "      <th>age</th>\n",
       "      <th>season</th>\n",
       "      <th>amount_tsh_missing</th>\n",
       "      <th>region_district</th>\n",
       "      <th>authority_scheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>functional</td>\n",
       "      <td>roman</td>\n",
       "      <td>roman</td>\n",
       "      <td>-9.86</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>34.94</td>\n",
       "      <td>0</td>\n",
       "      <td>VWC</td>\n",
       "      <td>1390</td>\n",
       "      <td>109</td>\n",
       "      <td>12</td>\n",
       "      <td>long rain</td>\n",
       "      <td>0</td>\n",
       "      <td>Iringa-5</td>\n",
       "      <td>non-autonomous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>functional</td>\n",
       "      <td>grumeti</td>\n",
       "      <td>grumeti</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>34.70</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>1399</td>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>long rain</td>\n",
       "      <td>1</td>\n",
       "      <td>Mara-2</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>functional</td>\n",
       "      <td>other</td>\n",
       "      <td>world vision</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>37.46</td>\n",
       "      <td>1</td>\n",
       "      <td>VWC</td>\n",
       "      <td>686</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>short dry</td>\n",
       "      <td>0</td>\n",
       "      <td>Manyara-4</td>\n",
       "      <td>non-autonomous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>non functional</td>\n",
       "      <td>unicef</td>\n",
       "      <td>unicef</td>\n",
       "      <td>-11.16</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>38.49</td>\n",
       "      <td>1</td>\n",
       "      <td>VWC</td>\n",
       "      <td>263</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>short dry</td>\n",
       "      <td>1</td>\n",
       "      <td>Mtwara-63</td>\n",
       "      <td>non-autonomous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>functional</td>\n",
       "      <td>other</td>\n",
       "      <td>artisan</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>31.13</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>1328</td>\n",
       "      <td>532</td>\n",
       "      <td>15</td>\n",
       "      <td>long dry</td>\n",
       "      <td>1</td>\n",
       "      <td>Kagera-1</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group   funder     installer  latitude  \\\n",
       "0  69572      functional    roman         roman     -9.86   \n",
       "1   8776      functional  grumeti       grumeti     -2.15   \n",
       "2  34310      functional    other  world vision     -3.82   \n",
       "3  67743  non functional   unicef        unicef    -11.16   \n",
       "4  19728      functional    other       artisan     -1.83   \n",
       "\n",
       "                     basin region_code  public_meeting extraction_type  \\\n",
       "0               Lake Nyasa          11               1         gravity   \n",
       "1            Lake Victoria          20               1         gravity   \n",
       "2                  Pangani          21               1         gravity   \n",
       "3  Ruvuma / Southern Coast          90               1     submersible   \n",
       "4            Lake Victoria          18               1         gravity   \n",
       "\n",
       "  extraction_type_class payment_type water_quality      quantity  \\\n",
       "0               gravity     annually          soft        enough   \n",
       "1               gravity    never pay          soft  insufficient   \n",
       "2               gravity   per bucket          soft        enough   \n",
       "3           submersible    never pay          soft           dry   \n",
       "4               gravity    never pay          soft      seasonal   \n",
       "\n",
       "                 source              waterpoint_type  longitude  permit  \\\n",
       "0                spring           communal standpipe      34.94       0   \n",
       "1  rainwater harvesting           communal standpipe      34.70       1   \n",
       "2                   dam  communal standpipe multiple      37.46       1   \n",
       "3           machine dbh  communal standpipe multiple      38.49       1   \n",
       "4  rainwater harvesting           communal standpipe      31.13       1   \n",
       "\n",
       "  scheme_management  gps_height  population  age     season  \\\n",
       "0               VWC        1390         109   12  long rain   \n",
       "1             Other        1399         280    3  long rain   \n",
       "2               VWC         686         250    4  short dry   \n",
       "3               VWC         263          58   27  short dry   \n",
       "4             Other        1328         532   15   long dry   \n",
       "\n",
       "   amount_tsh_missing region_district authority_scheme  \n",
       "0                   0        Iringa-5   non-autonomous  \n",
       "1                   1          Mara-2            other  \n",
       "2                   0       Manyara-4   non-autonomous  \n",
       "3                   1       Mtwara-63   non-autonomous  \n",
       "4                   1        Kagera-1            other  "
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#during EDA I already decided what features to keep and which ones to drop\n",
    "train_df = train_df.drop(['amount_tsh', 'date_recorded', 'wpt_name', 'num_private', 'subvillage', 'region',  'district_code', 'lga', 'ward', 'recorded_by', 'scheme_name', 'extraction_type_group', 'management', 'management_group', 'payment', 'quality_group', 'quantity_group', 'source_class', 'source_type', 'waterpoint_type_group', 'construction_year'], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encoding\n",
    "Remove bad features here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train and test \n",
    "train_set = train_df[train_df [\"id\"].isin(train_base_df[\"id\"])]\n",
    "test_set =  train_df[train_df  [\"id\"].isin(test_df[\"id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop(['id', 'status_group'], axis=1)\n",
    "y = train_set['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funder', 'installer', 'latitude', 'basin', 'region_code',\n",
       "       'public_meeting', 'extraction_type', 'extraction_type_class',\n",
       "       'payment_type', 'water_quality', 'quantity', 'source',\n",
       "       'waterpoint_type', 'longitude', 'permit', 'scheme_management',\n",
       "       'gps_height', 'population', 'age', 'season', 'amount_tsh_missing',\n",
       "       'region_district', 'authority_scheme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [cname for cname in X .columns if\n",
    "                   X [cname].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set[col] = le.fit_transform(train_set[col])\n",
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3744793663.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[col] = le.transform(test_set[col])\n"
     ]
    }
   ],
   "source": [
    "# Encode Categorical Columns \n",
    "for col in categorical_cols:\n",
    "  le = LabelEncoder()\n",
    "  train_set[col] = le.fit_transform(train_set[col])\n",
    "  test_set[col] = le.transform(test_set[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_50619/3238694098.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_set.append(test_set)\n"
     ]
    }
   ],
   "source": [
    "#merge the encoded train and test sets together\n",
    "train_df = train_set.append(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"final1_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'status_group', 'funder', 'installer', 'latitude', 'basin',\n",
       "       'region_code', 'public_meeting', 'extraction_type',\n",
       "       'extraction_type_class', 'payment_type', 'water_quality', 'quantity',\n",
       "       'source', 'waterpoint_type', 'longitude', 'permit', 'scheme_management',\n",
       "       'gps_height', 'population', 'age', 'season', 'amount_tsh_missing',\n",
       "       'region_district', 'authority_scheme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
