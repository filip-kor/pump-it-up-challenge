{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_impute_latitude = False\n",
    "sw_population_bins = False\n",
    "sw_data_leakage = True\n",
    "sw_region_target_encoding = False\n",
    "sw_oversampling = False\n",
    "sw_extraction_type_class_eng = False\n",
    "sw_gps_height_model_imput = False\n",
    "sw_gps_height_reduce_card = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_checker (data, xlabel):\n",
    "  grouped = data.groupby([xlabel, 'status_group'])['id'].count().reset_index()\n",
    "  pivot = grouped.pivot_table(index = xlabel, columns = 'status_group', fill_value = 0)\n",
    "  mi=pivot.columns\n",
    "  mi.tolist()\n",
    "  ind = pd.Index([ str(e[1])  for e in mi.tolist()])\n",
    "  pivot.columns = ind\n",
    "  pivot['nr_pumps'] = pivot['functional'] +pivot['functional needs repair'] +pivot['non functional']\n",
    "  pivot['all_pumps'] = pivot['nr_pumps'].sum()\n",
    "  pivot['perc_total_pumps'] =((pivot['nr_pumps']/pivot['all_pumps'])*100).round(1)\n",
    "  pivot['perc_functional'] = ((pivot['functional']/pivot['nr_pumps'])*100).round(1)\n",
    "  pivot['perc_non_functional'] = ((pivot['non functional']/pivot['nr_pumps'])*100).round(1)\n",
    "  pivot['perc_functional_needs_repair'] = ((pivot['functional needs repair']/pivot['nr_pumps'])*100).round(1)\n",
    "  pivot = pivot.drop(['functional', 'functional needs repair', 'non functional', 'all_pumps'], axis=1)\n",
    "  return(pivot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Includes imputation and deletion of bad features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: \n",
      " ['id', 'amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'region_code', 'district_code', 'population', 'construction_year']\n"
     ]
    }
   ],
   "source": [
    "train_base_df = pd.read_csv(\"project/data/train/features.csv\", parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "labels = pd.read_csv(\"project/data/train/labels.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"project/data/test/test.csv\", parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "\n",
    "# Merge features and labels files\n",
    "train_df = pd.merge(labels, train_base_df, on='id')\n",
    "\n",
    "print(\"Numerical columns: \\n\", train_df.select_dtypes(include=np.number).columns.tolist())\n",
    "\n",
    "# Introducing: DATA LEAKAGE\n",
    "if sw_data_leakage:\n",
    "    train_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>functional</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Mnyusi B</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ludewa</td>\n",
       "      <td>Mundindi</td>\n",
       "      <td>109.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Roman</td>\n",
       "      <td>False</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay annually</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Nyamara</td>\n",
       "      <td>Mara</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Serengeti</td>\n",
       "      <td>Natta</td>\n",
       "      <td>280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>wug</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>functional</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686.0</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Majengo</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Simanjiro</td>\n",
       "      <td>Ngorika</td>\n",
       "      <td>250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Nyumba ya mungu pipe scheme</td>\n",
       "      <td>True</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay per bucket</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>non functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263.0</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mahakamani</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>90</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>functional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kyanyamisa</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Karagwe</td>\n",
       "      <td>Nyakasimbi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group  amount_tsh date_recorded        funder  gps_height  \\\n",
       "0  69572      functional      6000.0    2011-03-14         Roman      1390.0   \n",
       "1   8776      functional         NaN    2013-03-06       Grumeti      1399.0   \n",
       "2  34310      functional        25.0    2013-02-25  Lottery Club       686.0   \n",
       "3  67743  non functional         NaN    2013-01-28        Unicef       263.0   \n",
       "4  19728      functional         NaN    2011-07-13   Action In A         NaN   \n",
       "\n",
       "      installer  longitude   latitude              wpt_name  num_private  \\\n",
       "0         Roman  34.938093  -9.856322                  none          NaN   \n",
       "1       GRUMETI  34.698766  -2.147466              Zahanati          NaN   \n",
       "2  World vision  37.460664  -3.821329           Kwa Mahundi          NaN   \n",
       "3        UNICEF  38.486161 -11.155298  Zahanati Ya Nanyumbu          NaN   \n",
       "4       Artisan  31.130847  -1.825359               Shuleni          NaN   \n",
       "\n",
       "                     basin  subvillage   region  region_code  district_code  \\\n",
       "0               Lake Nyasa    Mnyusi B   Iringa           11            5.0   \n",
       "1            Lake Victoria     Nyamara     Mara           20            2.0   \n",
       "2                  Pangani     Majengo  Manyara           21            4.0   \n",
       "3  Ruvuma / Southern Coast  Mahakamani   Mtwara           90           63.0   \n",
       "4            Lake Victoria  Kyanyamisa   Kagera           18            1.0   \n",
       "\n",
       "         lga        ward  population public_meeting              recorded_by  \\\n",
       "0     Ludewa    Mundindi       109.0           True  GeoData Consultants Ltd   \n",
       "1  Serengeti       Natta       280.0            NaN  GeoData Consultants Ltd   \n",
       "2  Simanjiro     Ngorika       250.0           True  GeoData Consultants Ltd   \n",
       "3   Nanyumbu    Nanyumbu        58.0           True  GeoData Consultants Ltd   \n",
       "4    Karagwe  Nyakasimbi         NaN           True  GeoData Consultants Ltd   \n",
       "\n",
       "  scheme_management                  scheme_name permit  construction_year  \\\n",
       "0               VWC                        Roman  False             1999.0   \n",
       "1             Other                          NaN   True             2010.0   \n",
       "2               VWC  Nyumba ya mungu pipe scheme   True             2009.0   \n",
       "3               VWC                          NaN   True             1986.0   \n",
       "4               NaN                          NaN   True                NaN   \n",
       "\n",
       "  extraction_type extraction_type_group extraction_type_class management  \\\n",
       "0         gravity               gravity               gravity        vwc   \n",
       "1         gravity               gravity               gravity        wug   \n",
       "2         gravity               gravity               gravity        vwc   \n",
       "3     submersible           submersible           submersible        vwc   \n",
       "4         gravity               gravity               gravity      other   \n",
       "\n",
       "  management_group         payment payment_type water_quality quality_group  \\\n",
       "0       user-group    pay annually     annually          soft          good   \n",
       "1       user-group       never pay    never pay          soft          good   \n",
       "2       user-group  pay per bucket   per bucket          soft          good   \n",
       "3       user-group       never pay    never pay          soft          good   \n",
       "4            other       never pay    never pay          soft          good   \n",
       "\n",
       "       quantity quantity_group                source           source_type  \\\n",
       "0        enough         enough                spring                spring   \n",
       "1  insufficient   insufficient  rainwater harvesting  rainwater harvesting   \n",
       "2        enough         enough                   dam                   dam   \n",
       "3           dry            dry           machine dbh              borehole   \n",
       "4      seasonal       seasonal  rainwater harvesting  rainwater harvesting   \n",
       "\n",
       "  source_class              waterpoint_type waterpoint_type_group  \n",
       "0  groundwater           communal standpipe    communal standpipe  \n",
       "1      surface           communal standpipe    communal standpipe  \n",
       "2      surface  communal standpipe multiple    communal standpipe  \n",
       "3  groundwater  communal standpipe multiple    communal standpipe  \n",
       "4      surface           communal standpipe    communal standpipe  "
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_private          98.7\n",
       "amount_tsh           70.1\n",
       "scheme_name          47.5\n",
       "population           36.1\n",
       "construction_year    35.0\n",
       "gps_height           34.5\n",
       "status_group         20.0\n",
       "installer             7.4\n",
       "funder                7.4\n",
       "scheme_management     6.5\n",
       "public_meeting        5.6\n",
       "permit                5.1\n",
       "longitude             3.1\n",
       "subvillage            0.6\n",
       "payment_type          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = round((train_df.isna().sum())/len(train_df)*100,1)\n",
    "missing = missing.sort_values(ascending = False)\n",
    "missing.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longitude Imputation\n",
    "\n",
    "0 values are replaced by subvillage, ward, lga, or region's mean logitude values for each column. \n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2269"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['longitude'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>longitude_imputed_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arusha</td>\n",
       "      <td>36.554067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dar es Salaam</td>\n",
       "      <td>39.212935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dodoma</td>\n",
       "      <td>36.041964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iringa</td>\n",
       "      <td>34.895921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kagera</td>\n",
       "      <td>31.233092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          region  longitude_imputed_region\n",
       "0         Arusha                 36.554067\n",
       "1  Dar es Salaam                 39.212935\n",
       "2         Dodoma                 36.041964\n",
       "3         Iringa                 34.895921\n",
       "4         Kagera                 31.233092"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df['longitude'].replace(0, np.nan, inplace=True)\n",
    "#create mean longitude on the lowest granularity level (subvillage)\n",
    "means_longitude_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['longitude'].mean().reset_index()\n",
    "means_longitude_subvillage = means_longitude_subvillage.rename(columns={\"longitude\": \"longitude_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_longitude_ward = train_df.groupby(['region', 'lga', 'ward',])['longitude'].mean().reset_index()\n",
    "means_longitude_ward = means_longitude_ward.rename(columns={\"longitude\": \"longitude_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_longitude_lga = train_df.groupby(['region', 'lga'])['longitude'].mean().reset_index()\n",
    "means_longitude_lga = means_longitude_lga .rename(columns={\"longitude\": \"longitude_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_longitude_region = train_df.groupby(['region'])['longitude'].mean().reset_index()\n",
    "means_longitude_region = means_longitude_region.rename(columns={\"longitude\": \"longitude_imputed_region\"})\n",
    "means_longitude_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the aggregated dataframes as new columns to the original df\n",
    "train_df= train_df.merge(means_longitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "train_df= train_df.merge(means_longitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "train_df = train_df.merge(means_longitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "train_df = train_df.merge(means_longitude_region, how = 'left', on = ['region'])\n",
    "\n",
    "#select the right longitude level based on the availability of information\n",
    "train_df['imputed_longitude'] = np.where(train_df['longitude'].isna(), train_df['longitude_imputed_subvillage'], train_df['longitude']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_ward'], train_df['imputed_longitude']) #if subvillage mean is missing, impute it by the ward\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_lga'], train_df['imputed_longitude'])\n",
    "train_df['imputed_longitude'] = np.where(train_df['imputed_longitude'].isna(), train_df['longitude_imputed_region'], train_df['imputed_longitude'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['longitude_imputed_subvillage','longitude_imputed_ward' , 'longitude_imputed_lga' , 'longitude_imputed_region', 'longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['imputed_longitude'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude Imputation\n",
    "\n",
    "0 values are replaced by subvillage, ward, lga, or region's mean latitude values for each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2269"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['latitude'].where(df[\"latitude\"] <= -0.5, np.nan, inplace=True)\n",
    "df['latitude'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>latitude_imputed_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arusha</td>\n",
       "      <td>-3.245240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dar es Salaam</td>\n",
       "      <td>-6.908390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dodoma</td>\n",
       "      <td>-5.940758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iringa</td>\n",
       "      <td>-8.908507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kagera</td>\n",
       "      <td>-1.960664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          region  latitude_imputed_region\n",
       "0         Arusha                -3.245240\n",
       "1  Dar es Salaam                -6.908390\n",
       "2         Dodoma                -5.940758\n",
       "3         Iringa                -8.908507\n",
       "4         Kagera                -1.960664"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create mean latitude on the lowest granularity level (subvillage)\n",
    "means_latitude_subvillage = df.groupby(['region', 'lga', 'ward', 'subvillage'])['latitude'].mean().reset_index()\n",
    "means_latitude_subvillage = means_latitude_subvillage.rename(columns={\"latitude\": \"latitude_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_latitude_ward = df.groupby(['region', 'lga', 'ward',])['latitude'].mean().reset_index()\n",
    "means_latitude_ward = means_latitude_ward.rename(columns={\"latitude\": \"latitude_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_latitude_lga = df.groupby(['region', 'lga'])['latitude'].mean().reset_index()\n",
    "means_latitude_lga = means_latitude_lga .rename(columns={\"latitude\": \"latitude_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_latitude_region = df.groupby(['region'])['latitude'].mean().reset_index()\n",
    "means_latitude_region = means_latitude_region.rename(columns={\"latitude\": \"latitude_imputed_region\"})\n",
    "means_latitude_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the aggregated dataframes as new columns to the original df\n",
    "df = df.merge(means_latitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "df = df.merge(means_latitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "df = df.merge(means_latitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "df = df.merge(means_latitude_region, how = 'left', on = ['region'])\n",
    "\n",
    "#select the right latitude level based on the availability of information\n",
    "df['imputed_latitude'] = np.where(df['latitude'].isna(), df['latitude_imputed_subvillage'], df['latitude']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "df['imputed_latitude'] = np.where(df['imputed_latitude'].isna(), df['latitude_imputed_ward'], df['imputed_latitude']) #if subvillage mean is missing, impute it by the ward\n",
    "df['imputed_latitude'] = np.where(df['imputed_latitude'].isna(), df['latitude_imputed_lga'], df['imputed_latitude'])\n",
    "df['imputed_latitude'] = np.where(df['imputed_latitude'].isna(), df['latitude_imputed_region'], df['imputed_latitude'])\n",
    "\n",
    "#drop redundant columns\n",
    "df= df.drop(['latitude_imputed_subvillage','latitude_imputed_ward' , 'latitude_imputed_lga' , 'latitude_imputed_region', 'latitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['imputed_latitude'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create density plot\n",
    "def impute_checker (feature, imputed_dataset, title):\n",
    "  train_df[feature].plot(kind='kde', c='black')\n",
    "  imputed_dataset[feature].plot(kind='kde', style = \"--\", c= '#66c2a5')\n",
    "  labels = ['Original df', 'Imputed df']\n",
    "  plt.legend(labels)\n",
    "  plt.xlabel(feature)\n",
    "  plt.title(title)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sw_impute_latitude:\n",
    "    train_df = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permit Imputation\n",
    "Impute missing values with mode of similar records. `management_group` and `public_meeting` were used by BrendaLoznik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute by mode\n",
    "permit_mg_mode= train_df.groupby(['public_meeting', 'management_group'])['permit'].agg(pd.Series.mode).reset_index()\n",
    "permit_mg_mode  = permit_mg_mode.rename(columns={\"permit\": \"imputed_permit_mg\"})\n",
    "train_df = train_df.merge(permit_mg_mode, how = 'left', on = ['public_meeting', 'management_group'])\n",
    "\n",
    "train_df['imputed_permit'] = np.where(train_df['permit'].isna(), train_df['imputed_permit_mg'], train_df['permit'])  #if permit is missing, replace it by the mode of public meeting - management group\n",
    "train_df['imputed_permit']  = np.where(train_df['imputed_permit'] .isna(), train_df['permit'].mode(), train_df['imputed_permit'])  #if eitther public meeting or management group is missing, then use the mode of permit (True)\n",
    "\n",
    "#drop original permit column\n",
    "train_df = train_df.drop(['permit', 'imputed_permit_mg'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Meeting Imputation\n",
    "Simply impute public_meeting with the mode, as 90% of pumps have a TRUE value\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_meeting_mode = train_df['public_meeting'].mode()[0]\n",
    "train_df['public_meeting'] = train_df['public_meeting'].fillna(public_meeting_mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheme Management Imputation\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems like a logical choice to impute missing scheme management values by the mode of the management - scheme-management as there is a lot of overlap here\n",
    "check = train_df.groupby([  'management_group', 'scheme_management' , 'management'])['id'].count().reset_index()\n",
    "check = check.sort_values('management')\n",
    "check.head(10)\n",
    "\n",
    "scheme_mode = train_df.groupby(['management'])['scheme_management'].agg(pd.Series.mode).reset_index()\n",
    "scheme_mode = scheme_mode.rename(columns={\"scheme_management\": \"imputed_scheme_management\"})\n",
    "scheme_mode \n",
    "\n",
    "#merge scheme_mode to original df and use it to replace missing values\n",
    "train_df = train_df.merge(scheme_mode, how = 'left', on = [ 'management'])\n",
    "train_df['imputed_scheme__management'] = np.where(train_df['scheme_management'].isna(), train_df['imputed_scheme_management'], train_df['scheme_management'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['scheme_management', 'imputed_scheme_management'],axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installer\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed a lot of variation in captialization, so I will first convert al entries to lowercase\n",
    "train_df['installer'] = train_df['installer'].str.lower()\n",
    "\n",
    "#plot top 10 installers\n",
    "installer = train_df.groupby('installer')['id'].count().reset_index()\n",
    "installer = installer.sort_values('id', ascending = False)\n",
    "installer.head(10)\n",
    "\n",
    "\n",
    "#there are a few categories in the top 60 most common categories whose naims look a lot alike and are probably typo's. We will merge them together\n",
    "train_df['installer'] = np.where( train_df['installer']=='gove', 'gover', train_df['installer'] )\n",
    "train_df['installer'] = np.where( train_df['installer']=='community', 'commu', train_df['installer'] )\n",
    "train_df['installer'] = np.where( train_df['installer']=='danid', 'danida', train_df['installer'] )\n",
    "\n",
    "installer = train_df.groupby('installer')['id'].count().reset_index()\n",
    "installer = installer.sort_values('id', ascending = False)\n",
    "installer.head(10)\n",
    "\n",
    "#I want to keep the most frequent installers and combine the rarer classes together. I have played around with the optimum number of installers to keep, and I decided on the top 150.\n",
    "\n",
    "#create list of top 150 installers\n",
    "top_installers = installer.nlargest(150, 'id')['installer'].unique()\n",
    "\n",
    "#replace funders that are not in top 10 with 'other'\n",
    "train_df['installer'] = np.where(train_df['installer'].isin(top_installers), train_df['installer'], 'other')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funder\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set all entries to lowercase\n",
    "train_df['funder'] = train_df['funder'].str.lower()\n",
    "\n",
    "\n",
    "funder = train_df.groupby('funder')['id'].count().reset_index()\n",
    "funder = funder.sort_values('id', ascending = False)\n",
    "funder.head(10)\n",
    "\n",
    "#create list of top 150 funders\n",
    "top_funders = funder.nlargest(150, 'id')['funder'].unique()\n",
    "\n",
    "#replace funders that are not in top 150 with 'other'\n",
    "train_df['funder'] = np.where(train_df['funder'].isin(top_funders), train_df['funder'], 'other')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Year Imputation\n",
    "\n",
    "Since `extraction_type_group` is associated with `construction_year`, that will help to impute the values.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because of the wide spread of construction years, I don't want to impude by the overall mean\n",
    "train_df['construction_year'].min(),  train_df['construction_year'].max() , train_df['construction_year'].mean()\n",
    "\n",
    "#We can see that the mean construction year by extraction type group gives much more detailed information\n",
    "mean_construction = train_df.groupby('extraction_type_group')['construction_year'].mean().reset_index()\n",
    "\n",
    "#create train_df with the mean extraction year by extraction type group\n",
    "mean_construction = train_df.groupby('extraction_type_group')['construction_year'].mean().reset_index()\n",
    "mean_construction  = mean_construction .rename(columns={\"construction_year\": \"imputed_construction_year\"})\n",
    "\n",
    "#merge this train_df to the main train_df and replace missing values\n",
    "train_df = train_df.merge(mean_construction, how =  'left', on =  'extraction_type_group')\n",
    "train_df['construction_year_imputed'] = np.where(train_df['construction_year'].isna(), train_df['imputed_construction_year'], train_df['construction_year'] )\n",
    "\n",
    "#drop redundant columns\n",
    "train_df=train_df.drop(['imputed_construction_year', 'construction_year'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPS Height Imputation\n",
    "\n",
    "Replace values randomly within 1std of the mean, following a normal distribution.\n",
    "\n",
    "This probably needs verifying/improving but it'll do for now.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sw_gps_height_model_imput:\n",
    "    #create mean on the lowest granularity level (subvillage)\n",
    "    means_altitude_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['gps_height'].mean().reset_index()#\n",
    "    means_altitude_subvillage = means_altitude_subvillage.rename(columns={\"gps_height\": \"gps_height_imputed_subvillage\"})\n",
    "\n",
    "    #ward level\n",
    "    means_altitude_ward = train_df.groupby(['region', 'lga', 'ward',])['gps_height'].mean().reset_index()\n",
    "    means_altitude_ward = means_altitude_ward.rename(columns={\"gps_height\": \"gps_height_imputed_ward\"})\n",
    "\n",
    "    #lga level\n",
    "    means_altitude_lga = train_df.groupby(['region', 'lga'])['gps_height'].mean().reset_index()\n",
    "    means_altitude_lga = means_altitude_lga .rename(columns={\"gps_height\": \"gps_height_imputed_lga\"})\n",
    "\n",
    "    #region level\n",
    "    means_altitude_region = train_df.groupby(['region'])['gps_height'].mean().reset_index()\n",
    "    means_altitude_region = means_altitude_region.rename(columns={\"gps_height\": \"gps_height_imputed_region\"})\n",
    "\n",
    "    #region basin\n",
    "    means_altitude_basin = train_df.groupby(['basin'])['gps_height'].mean().reset_index()\n",
    "    means_altitude_basin = means_altitude_basin.rename(columns={\"gps_height\": \"gps_height_imputed_basin\"})\n",
    "\n",
    "    #merge the aggregated dataframes as new columns to the original train_df\n",
    "    train_df= train_df.merge(means_altitude_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "    train_df = train_df.merge(means_altitude_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "    train_df = train_df.merge(means_altitude_lga, how = 'left', on = ['region', 'lga'])\n",
    "    train_df = train_df.merge(means_altitude_region, how = 'left', on = ['region'])\n",
    "    train_df = train_df.merge(means_altitude_basin, how = 'left', on = ['basin'])\n",
    "\n",
    "    #create final imputed longitude column\n",
    "    train_df['imputed_gps_height'] = np.where(train_df['gps_height'].isna(), train_df['gps_height_imputed_subvillage'], train_df['gps_height']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "    train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_ward'], train_df['imputed_gps_height']) #if subvillage mean is missing, impute it by the ward\n",
    "    train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_lga'], train_df['imputed_gps_height'])\n",
    "    train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_region'], train_df['imputed_gps_height'])\n",
    "    train_df['imputed_gps_height'] = np.where(train_df['imputed_gps_height'].isna(), train_df['gps_height_imputed_basin'], train_df['imputed_gps_height'])\n",
    "\n",
    "    #drop redundant columns\n",
    "    train_df= train_df.drop(['gps_height_imputed_subvillage','gps_height_imputed_ward' , 'gps_height_imputed_lga' , 'gps_height_imputed_region', 'gps_height', 'gps_height_imputed_basin'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "if sw_gps_height_model_imput:\n",
    "\n",
    "    df = train_df.copy()\n",
    "\n",
    "    if sw_impute_latitude:\n",
    "        latitude = 'imputed_latitude'\n",
    "    else:\n",
    "        latitude = 'latitude'\n",
    "\n",
    "    # Specify the path to the SRTM file for Tanzania\n",
    "    srtm_file = \"Tanzania_SRTM30meters.tif\"\n",
    "\n",
    "    # Create a mask for rows where 'gps_height' is null\n",
    "    null_height_mask = df['gps_height'].isna()\n",
    "\n",
    "    # Retrieve the elevation values for rows with null 'gps_height'\n",
    "    elevations = []\n",
    "\n",
    "    with rasterio.open(srtm_file) as dataset:\n",
    "        elevation_data = dataset.read(1)\n",
    "\n",
    "        for idx, row in df[null_height_mask].iterrows():\n",
    "            # Transform latitude and longitude to pixel coordinates\n",
    "            row_idx, col_idx = dataset.index(row['imputed_longitude'], row[latitude])\n",
    "            # Read the elevation value at the pixel coordinates\n",
    "            elevation = elevation_data[row_idx, col_idx]\n",
    "            elevations.append(elevation)\n",
    "\n",
    "    # Assign the retrieved elevations to the 'gps_height' column\n",
    "    df.loc[null_height_mask, 'gps_height'] = elevations\n",
    "\n",
    "\n",
    "    train_df['imputed_gps_height'] = df['gps_height']\n",
    "    train_df= train_df.drop('gps_height', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'status_group', 'amount_tsh', 'date_recorded', 'funder',\n",
       "       'installer', 'latitude', 'wpt_name', 'num_private', 'basin',\n",
       "       'subvillage', 'region', 'region_code', 'district_code', 'lga', 'ward',\n",
       "       'population', 'public_meeting', 'recorded_by', 'scheme_name',\n",
       "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
       "       'management', 'management_group', 'payment', 'payment_type',\n",
       "       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n",
       "       'source', 'source_type', 'source_class', 'waterpoint_type',\n",
       "       'waterpoint_type_group', 'imputed_longitude', 'imputed_permit',\n",
       "       'imputed_scheme__management', 'construction_year_imputed',\n",
       "       'imputed_gps_height'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population\n",
    "Brenda's solution considers region-wide population average when not available, which is a poor indicator of population. Some readings also have very large population values, which skew the average. We use a binning approach to better represent population, with a \"missing\" bin where subvillage or ward population is unknown, as this itself is a decent predictor.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mean on the lowest granularity level (subvillage)\n",
    "means_population_subvillage = train_df.groupby(['region', 'lga', 'ward', 'subvillage'])['population'].mean().reset_index()#\n",
    "means_population_subvillage = means_population_subvillage.rename(columns={\"population\": \"population_imputed_subvillage\"})\n",
    "\n",
    "#ward level\n",
    "means_population_ward = train_df.groupby(['region', 'lga', 'ward',])['population'].mean().reset_index()\n",
    "means_population_ward = means_population_ward.rename(columns={\"population\": \"population_imputed_ward\"})\n",
    "\n",
    "#lga level\n",
    "means_population_lga = train_df.groupby(['region', 'lga'])['population'].mean().reset_index()\n",
    "means_population_lga = means_population_lga .rename(columns={\"population\": \"population_imputed_lga\"})\n",
    "\n",
    "#region level\n",
    "means_population_region = train_df.groupby(['region'])['population'].mean().reset_index()\n",
    "means_population_region = means_population_region.rename(columns={\"population\": \"population_imputed_region\"})\n",
    "\n",
    "#region basin\n",
    "means_population_basin = train_df.groupby(['basin'])['population'].mean().reset_index()\n",
    "means_population_basin = means_population_basin.rename(columns={\"population\": \"population_imputed_basin\"})\n",
    "\n",
    "#merge the aggregated dataframes as new columns to the original df\n",
    "train_df= train_df.merge(means_population_subvillage, how = 'left', on = ['region', 'lga', 'ward', 'subvillage'])\n",
    "train_df = train_df.merge(means_population_ward, how = 'left', on = ['region', 'lga', 'ward'])\n",
    "train_df = train_df.merge(means_population_lga, how = 'left', on = ['region', 'lga'])\n",
    "train_df = train_df.merge(means_population_region, how = 'left', on = ['region'])\n",
    "train_df = train_df.merge(means_population_basin, how = 'left', on = ['basin'])\n",
    "\n",
    "#create final imputed longitude column\n",
    "train_df['imputed_population'] = np.where(train_df['population'].isna(), train_df['population_imputed_subvillage'], train_df['population']) #if longitude is missing, impute it by the mean of the subvillage\n",
    "train_df['imputed_population'] = np.where(train_df['imputed_population'].isna(), train_df['population_imputed_ward'], train_df['imputed_population']) #if subvillage mean is missing, impute it by the ward\n",
    "train_df['imputed_population'] = np.where(train_df['imputed_population'].isna(), train_df['population_imputed_lga'], train_df['imputed_population'])\n",
    "train_df['imputed_population'] = np.where(train_df['imputed_population'].isna(), train_df['population_imputed_region'], train_df['imputed_population'])\n",
    "train_df['imputed_population'] = np.where(train_df['imputed_population'].isna(), train_df['population_imputed_basin'], train_df['imputed_population'])\n",
    "\n",
    "#drop redundant columns\n",
    "train_df= train_df.drop(['population_imputed_subvillage','population_imputed_ward' , 'population_imputed_lga' , 'population_imputed_region', 'population', 'population_imputed_basin'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct data types\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace string to integer\n",
    "train_df['public_meeting'] = train_df['public_meeting'].replace({True: 1, False: 0})\n",
    "train_df['imputed_permit'] = train_df['imputed_permit'].replace({True: 1, False: 0})\n",
    "\n",
    "\n",
    "#change to integer\n",
    "train_df[['imputed_gps_height', 'construction_year_imputed', 'imputed_population']] = train_df[['imputed_gps_height', 'construction_year_imputed', 'imputed_population']].astype('int')\n",
    "\n",
    "#change type to categorical\n",
    "train_df[['region_code', 'district_code', 'num_private']] = train_df[['region_code', 'district_code', 'num_private']].astype('str')\n",
    "train_df[[ 'num_private']] = train_df[[ 'num_private']].astype('str')\n",
    "\n",
    "#remove decimal\n",
    "train_df['district_code'] = train_df['district_code'].str.split(\".\").str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned df\n",
    "train_df= train_df.rename(columns={\"imputed_permit\": \"permit\", \"imputed_scheme__management\": \"scheme_management\",\n",
    "                    \"imputed_gps_height\": \"gps_height\", 'construction_year_imputed': 'construction_year', \n",
    "                   'imputed_population': 'population', 'imputed_longitude': 'longitude'}, errors=\"raise\")\n",
    "\n",
    "if sw_impute_latitude:\n",
    "    train_df = train_df.rename(columns={'imputed_latitude': 'latitude'}, errors=\"raise\")\n",
    "\n",
    "train_df.to_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recorded_age Feature\n",
    "Create a feature recorded_age, which states the age (in years) of the pump at time of recording. Uses date_recorded and construction_year.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create age feature\n",
    "train_df['recorded_year'] = pd.DatetimeIndex(train_df ['date_recorded']).year\n",
    "train_df[ 'age'] = train_df['recorded_year'] - train_df['construction_year']\n",
    "train_df = train_df.drop('recorded_year',axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorded Season\n",
    "The month in which the water pump's functionality is recorded may be important due to wet/dry seasons in Tanzania. Due to the poor distribution of recorded months, we group months into different season bins.\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['month'] = pd.DatetimeIndex(train_df['date_recorded']).month\n",
    "\n",
    "# season encoder\n",
    "season_mapper = {1: 'short dry',2:'short dry', 3: 'long rain', 4: 'long rain', 5: 'long rain',6: 'long dry', \n",
    "                 7: 'long dry', 8: 'long dry', 9: 'long dry', 10: 'long dry', 11:'short rain', 12:'short rain'}\n",
    "#.p feature values to scale\n",
    "train_df['season'] = train_df['month'].replace(season_mapper)\n",
    "train_df = train_df.drop('month', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### amount_tsh missing\n",
    "Use a binary feature for whether amount_tsh is missing - this is a decent predictor of water pump status\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['amount_tsh_missing'] = np.where( train_df['amount_tsh'].isna(), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region District\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['region_district'] = train_df['region']+ \"-\" + train_df['district_code']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Cardinality of Longitude/Latitude\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two decimal places is 1.1 km accurate. This will provide enough information on the location. Using the full coordinate doesn't provide a lot of general information, but does result in high cardinality\n",
    "train_df['longitude'] = round(train_df['longitude'], 2)\n",
    "train_df['latitude'] = round(train_df['latitude'],2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Cardinality of GPS Height\n",
    "\n",
    "We round the height to tens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1390\n",
       "1        1399\n",
       "2         686\n",
       "3         263\n",
       "4        1328\n",
       "         ... \n",
       "74244      34\n",
       "74245     669\n",
       "74246    1476\n",
       "74247     998\n",
       "74248     481\n",
       "Name: gps_height, Length: 74249, dtype: int64"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['gps_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sw_gps_height_reduce_card:\n",
    "    train_df['gps_height'] = train_df['gps_height'].round(-1).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i want to keep extraction type class and I will group the extraction type group en type together\n",
    "\n",
    "#swn 80 and swn 81 become swn\n",
    "#cemo + climax become other motorpump\n",
    "# other -mkulima, other -play and walimi become other handpump\n",
    "\n",
    "swn = ['other - swn 81', 'swn80']\n",
    "train_df['extraction_type'] =np.where(train_df['extraction_type'].isin(swn), 'swn',  train_df['extraction_type'])\n",
    "\n",
    "other_handpump = ['other - mkulima/shinyanga', 'other - play pump', 'other - walimi']\n",
    "train_df['extraction_type']=np.where(train_df['extraction_type'].isin(other_handpump), 'other handpump',  train_df['extraction_type'])\n",
    "\n",
    "other_motorpump = ['cemo', 'climax']\n",
    "train_df['extraction_type'] =np.where(train_df['extraction_type'].isin(other_motorpump), 'other motorpump',  train_df['extraction_type'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Type Class\n",
    "\n",
    "There are very few datapoints with `wind-powered` and `rope pump`. Since `motorpump` has mostly similar label distribution to `wind-powered` and `rope pump` has mostly similar label distribution to `handpump`, we merge the former into the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_pumps</th>\n",
       "      <th>perc_total_pumps</th>\n",
       "      <th>perc_functional</th>\n",
       "      <th>perc_non_functional</th>\n",
       "      <th>perc_functional_needs_repair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gravity</th>\n",
       "      <td>26780</td>\n",
       "      <td>45.1</td>\n",
       "      <td>59.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handpump</th>\n",
       "      <td>16455</td>\n",
       "      <td>27.7</td>\n",
       "      <td>63.1</td>\n",
       "      <td>30.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motorpump</th>\n",
       "      <td>2987</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>6430</td>\n",
       "      <td>10.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rope pump</th>\n",
       "      <td>451</td>\n",
       "      <td>0.8</td>\n",
       "      <td>65.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submersible</th>\n",
       "      <td>6179</td>\n",
       "      <td>10.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind-powered</th>\n",
       "      <td>117</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42.7</td>\n",
       "      <td>51.3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nr_pumps  perc_total_pumps  perc_functional  \\\n",
       "extraction_type_class                                                \n",
       "gravity                   26780              45.1             59.9   \n",
       "handpump                  16455              27.7             63.1   \n",
       "motorpump                  2987               5.0             38.0   \n",
       "other                      6430              10.8             16.0   \n",
       "rope pump                   451               0.8             65.0   \n",
       "submersible                6179              10.4             53.9   \n",
       "wind-powered                117               0.2             42.7   \n",
       "\n",
       "                       perc_non_functional  perc_functional_needs_repair  \n",
       "extraction_type_class                                                     \n",
       "gravity                               30.0                          10.1  \n",
       "handpump                              30.9                           6.0  \n",
       "motorpump                             57.4                           4.6  \n",
       "other                                 80.8                           3.2  \n",
       "rope pump                             31.3                           3.8  \n",
       "submersible                           42.0                           4.1  \n",
       "wind-powered                          51.3                           6.0  "
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_df.copy()\n",
    "distribution_checker(df, 'extraction_type_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'wind-powered' class into 'motorpump'\n",
    "df['extraction_type_class'] = df['extraction_type_class'].replace('wind-powered', 'motorpump')\n",
    "\n",
    "# Merge 'rope pump' into 'handpump'\n",
    "df['extraction_type_class'] = df['extraction_type_class'].replace('rope pump', 'handpump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_pumps</th>\n",
       "      <th>perc_total_pumps</th>\n",
       "      <th>perc_functional</th>\n",
       "      <th>perc_non_functional</th>\n",
       "      <th>perc_functional_needs_repair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gravity</th>\n",
       "      <td>26780</td>\n",
       "      <td>45.1</td>\n",
       "      <td>59.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handpump</th>\n",
       "      <td>16906</td>\n",
       "      <td>28.5</td>\n",
       "      <td>63.1</td>\n",
       "      <td>30.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motorpump</th>\n",
       "      <td>3104</td>\n",
       "      <td>5.2</td>\n",
       "      <td>38.2</td>\n",
       "      <td>57.2</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>6430</td>\n",
       "      <td>10.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submersible</th>\n",
       "      <td>6179</td>\n",
       "      <td>10.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nr_pumps  perc_total_pumps  perc_functional  \\\n",
       "extraction_type_class                                                \n",
       "gravity                   26780              45.1             59.9   \n",
       "handpump                  16906              28.5             63.1   \n",
       "motorpump                  3104               5.2             38.2   \n",
       "other                      6430              10.8             16.0   \n",
       "submersible                6179              10.4             53.9   \n",
       "\n",
       "                       perc_non_functional  perc_functional_needs_repair  \n",
       "extraction_type_class                                                     \n",
       "gravity                               30.0                          10.1  \n",
       "handpump                              30.9                           6.0  \n",
       "motorpump                             57.2                           4.7  \n",
       "other                                 80.8                           3.2  \n",
       "submersible                           42.0                           4.1  "
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_checker(df, 'extraction_type_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sw_extraction_type_class_eng:\n",
    "    train_df = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autonomy\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autonomous = government, VWC, town council ..... also water authority?, parastatal (=state company)? SWC?\n",
    "#autonomous = WUA, WUG, board, trust, school\n",
    "#private = private, company\n",
    "\n",
    "non = ['VWC', 'Water authority', 'Parastatal', 'SWC']\n",
    "autonomous = ['WUG', 'WUA', 'Water Board', 'Trust']\n",
    "private = ['Company', 'Private operator']\n",
    "other = ['None', 'Other']\n",
    "\n",
    "train_df['authority_scheme'] = train_df['scheme_management']\n",
    "train_df.loc[train_df['authority_scheme'].isin(non),'authority_scheme']='non-autonomous'\n",
    "train_df.loc[train_df['authority_scheme'].isin(autonomous ),'authority_scheme']='autonomous'\n",
    "train_df.loc[train_df['authority_scheme'].isin(private),'authority_scheme']='private'\n",
    "train_df.loc[train_df['authority_scheme'].isin(other ),'authority_scheme']='other'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine rare features in `source`\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep source, but the rare classes will be put together\n",
    "other = ['other',  'unknown']\n",
    "train_df['source'] = np.where(train_df['source']=='unknown', 'other', train_df['source'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population\n",
    "\n",
    "Adding bins to reduce cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_pumps</th>\n",
       "      <th>perc_total_pumps</th>\n",
       "      <th>perc_functional</th>\n",
       "      <th>perc_non_functional</th>\n",
       "      <th>perc_functional_needs_repair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population_bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>large</th>\n",
       "      <td>9069</td>\n",
       "      <td>15.3</td>\n",
       "      <td>52.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>22339</td>\n",
       "      <td>37.6</td>\n",
       "      <td>50.5</td>\n",
       "      <td>40.5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>10487</td>\n",
       "      <td>17.7</td>\n",
       "      <td>60.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very large</th>\n",
       "      <td>1566</td>\n",
       "      <td>2.6</td>\n",
       "      <td>58.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very small</th>\n",
       "      <td>15938</td>\n",
       "      <td>26.8</td>\n",
       "      <td>56.3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nr_pumps  perc_total_pumps  perc_functional  \\\n",
       "population_bins                                                \n",
       "large                9069              15.3             52.3   \n",
       "medium              22339              37.6             50.5   \n",
       "small               10487              17.7             60.6   \n",
       "very large           1566               2.6             58.6   \n",
       "very small          15938              26.8             56.3   \n",
       "\n",
       "                 perc_non_functional  perc_functional_needs_repair  \n",
       "population_bins                                                     \n",
       "large                           40.0                           7.7  \n",
       "medium                          40.5                           9.0  \n",
       "small                           32.8                           6.6  \n",
       "very large                      36.7                           4.7  \n",
       "very small                      38.5                           5.3  "
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_df.copy()\n",
    "\n",
    "# bin the population column and assign labels\n",
    "bins = [0, 100, 200, 500, 1000, 100000]\n",
    "df['population_bins'] = pd.cut(df['population'], bins=bins, labels=['very small', 'small', 'medium', 'large', 'very large']).astype('object')\n",
    "\n",
    "df = df.drop('population', axis=1)\n",
    "\n",
    "distribution_checker(df, 'population_bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sw_population_bins:\n",
    "    train_df = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional target encoding\n",
    "\n",
    "Features `region`, `lga` are turned into a single variable and target encoded. Adding `ward`, `subvillage` to that would make cardinality increase cardinality too much, so they are dropped. The obtained feature has sequential property with higher values being associated with functional pumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the columns into a new column using the 'apply' method\n",
    "df['combined'] = df[['region', 'lga']].apply(lambda x: '-'.join(x.dropna().astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_pumps</th>\n",
       "      <th>perc_total_pumps</th>\n",
       "      <th>perc_functional</th>\n",
       "      <th>perc_non_functional</th>\n",
       "      <th>perc_functional_needs_repair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combined</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arusha-Arusha Rural</th>\n",
       "      <td>1252</td>\n",
       "      <td>2.1</td>\n",
       "      <td>69.9</td>\n",
       "      <td>26.3</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arusha-Arusha Urban</th>\n",
       "      <td>63</td>\n",
       "      <td>0.1</td>\n",
       "      <td>66.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arusha-Karatu</th>\n",
       "      <td>326</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arusha-Longido</th>\n",
       "      <td>310</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arusha-Meru</th>\n",
       "      <td>1009</td>\n",
       "      <td>1.7</td>\n",
       "      <td>65.1</td>\n",
       "      <td>31.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanga-Lushoto</th>\n",
       "      <td>694</td>\n",
       "      <td>1.2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>29.1</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanga-Mkinga</th>\n",
       "      <td>288</td>\n",
       "      <td>0.5</td>\n",
       "      <td>77.8</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanga-Muheza</th>\n",
       "      <td>334</td>\n",
       "      <td>0.6</td>\n",
       "      <td>65.6</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanga-Pangani</th>\n",
       "      <td>305</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.3</td>\n",
       "      <td>77.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanga-Tanga</th>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42.4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nr_pumps  perc_total_pumps  perc_functional  \\\n",
       "combined                                                           \n",
       "Arusha-Arusha Rural      1252               2.1             69.9   \n",
       "Arusha-Arusha Urban        63               0.1             66.7   \n",
       "Arusha-Karatu             326               0.5             96.9   \n",
       "Arusha-Longido            310               0.5             64.5   \n",
       "Arusha-Meru              1009               1.7             65.1   \n",
       "...                       ...               ...              ...   \n",
       "Tanga-Lushoto             694               1.2             62.4   \n",
       "Tanga-Mkinga              288               0.5             77.8   \n",
       "Tanga-Muheza              334               0.6             65.6   \n",
       "Tanga-Pangani             305               0.5             21.3   \n",
       "Tanga-Tanga                99               0.2             42.4   \n",
       "\n",
       "                     perc_non_functional  perc_functional_needs_repair  \n",
       "combined                                                                \n",
       "Arusha-Arusha Rural                 26.3                           3.8  \n",
       "Arusha-Arusha Urban                 22.2                          11.1  \n",
       "Arusha-Karatu                        2.8                           0.3  \n",
       "Arusha-Longido                      26.1                           9.4  \n",
       "Arusha-Meru                         31.7                           3.2  \n",
       "...                                  ...                           ...  \n",
       "Tanga-Lushoto                       29.1                           8.5  \n",
       "Tanga-Mkinga                        22.2                           0.0  \n",
       "Tanga-Muheza                        34.4                           0.0  \n",
       "Tanga-Pangani                       77.7                           1.0  \n",
       "Tanga-Tanga                         54.5                           3.0  \n",
       "\n",
       "[125 rows x 5 columns]"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_checker(df, 'combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of 'functional' label for each unique value in the 'combined' column\n",
    "target_percentage = df.groupby('combined')['status_group'].apply(lambda x: (x == 'functional').mean())\n",
    "\n",
    "# Map the target percentage encoding values back to the 'combined' column\n",
    "df['region_encoded'] = df['combined'].map(target_percentage)\n",
    "\n",
    "# Delete unnecessary columns\n",
    "df = df.drop('combined', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_pumps</th>\n",
       "      <th>perc_total_pumps</th>\n",
       "      <th>perc_functional</th>\n",
       "      <th>perc_non_functional</th>\n",
       "      <th>perc_functional_needs_repair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_encoded</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.069333</th>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.149425</th>\n",
       "      <td>291</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>75.3</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.157895</th>\n",
       "      <td>71</td>\n",
       "      <td>0.1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>67.6</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.158706</th>\n",
       "      <td>528</td>\n",
       "      <td>0.9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>67.6</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.173333</th>\n",
       "      <td>305</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.3</td>\n",
       "      <td>77.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.177866</th>\n",
       "      <td>193</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>62.2</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.180812</th>\n",
       "      <td>231</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>65.8</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.188437</th>\n",
       "      <td>358</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>65.4</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.190244</th>\n",
       "      <td>154</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.3</td>\n",
       "      <td>72.7</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.197183</th>\n",
       "      <td>158</td>\n",
       "      <td>0.3</td>\n",
       "      <td>26.6</td>\n",
       "      <td>73.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.197260</th>\n",
       "      <td>298</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>42.3</td>\n",
       "      <td>33.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.204461</th>\n",
       "      <td>210</td>\n",
       "      <td>0.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>73.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.205882</th>\n",
       "      <td>341</td>\n",
       "      <td>0.6</td>\n",
       "      <td>26.7</td>\n",
       "      <td>53.4</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.210983</th>\n",
       "      <td>266</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.227907</th>\n",
       "      <td>170</td>\n",
       "      <td>0.3</td>\n",
       "      <td>28.8</td>\n",
       "      <td>71.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.239437</th>\n",
       "      <td>392</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30.4</td>\n",
       "      <td>62.2</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.249531</th>\n",
       "      <td>438</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30.4</td>\n",
       "      <td>68.3</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.258462</th>\n",
       "      <td>260</td>\n",
       "      <td>0.4</td>\n",
       "      <td>32.3</td>\n",
       "      <td>54.6</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.270734</th>\n",
       "      <td>824</td>\n",
       "      <td>1.4</td>\n",
       "      <td>34.5</td>\n",
       "      <td>56.1</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                nr_pumps  perc_total_pumps  perc_functional  \\\n",
       "region_encoded                                                \n",
       "0.000000               1               0.0              0.0   \n",
       "0.069333             300               0.5              8.7   \n",
       "0.149425             291               0.5             17.9   \n",
       "0.157895              71               0.1             21.1   \n",
       "0.158706             528               0.9             19.5   \n",
       "0.173333             305               0.5             21.3   \n",
       "0.177866             193               0.3             23.3   \n",
       "0.180812             231               0.4             21.2   \n",
       "0.188437             358               0.6             24.6   \n",
       "0.190244             154               0.3             25.3   \n",
       "0.197183             158               0.3             26.6   \n",
       "0.197260             298               0.5             24.2   \n",
       "0.204461             210               0.4             26.2   \n",
       "0.205882             341               0.6             26.7   \n",
       "0.210983             266               0.4             27.4   \n",
       "0.227907             170               0.3             28.8   \n",
       "0.239437             392               0.7             30.4   \n",
       "0.249531             438               0.7             30.4   \n",
       "0.258462             260               0.4             32.3   \n",
       "0.270734             824               1.4             34.5   \n",
       "\n",
       "                perc_non_functional  perc_functional_needs_repair  \n",
       "region_encoded                                                     \n",
       "0.000000                      100.0                           0.0  \n",
       "0.069333                       86.3                           5.0  \n",
       "0.149425                       75.3                           6.9  \n",
       "0.157895                       67.6                          11.3  \n",
       "0.158706                       67.6                          12.9  \n",
       "0.173333                       77.7                           1.0  \n",
       "0.177866                       62.2                          14.5  \n",
       "0.180812                       65.8                          13.0  \n",
       "0.188437                       65.4                          10.1  \n",
       "0.190244                       72.7                           1.9  \n",
       "0.197183                       73.4                           0.0  \n",
       "0.197260                       42.3                          33.6  \n",
       "0.204461                       73.3                           0.5  \n",
       "0.205882                       53.4                          19.9  \n",
       "0.210983                       68.0                           4.5  \n",
       "0.227907                       71.2                           0.0  \n",
       "0.239437                       62.2                           7.4  \n",
       "0.249531                       68.3                           1.4  \n",
       "0.258462                       54.6                          13.1  \n",
       "0.270734                       56.1                           9.5  "
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_checker(df, 'region_encoded').sort_values('region_encoded').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sw_region_target_encoding:\n",
    "    train_df = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (Partial) Feature Selection\n",
    "Remove bad features here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns to Drop\n",
    "amount_tsh: *70% missing values*\n",
    "\n",
    "date_recorded: *Used in recorded_age engineered feature*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "      <th>funder</th>\n",
       "      <th>installer</th>\n",
       "      <th>latitude</th>\n",
       "      <th>basin</th>\n",
       "      <th>region_code</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>longitude</th>\n",
       "      <th>permit</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>population</th>\n",
       "      <th>age</th>\n",
       "      <th>season</th>\n",
       "      <th>amount_tsh_missing</th>\n",
       "      <th>region_district</th>\n",
       "      <th>authority_scheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>functional</td>\n",
       "      <td>roman</td>\n",
       "      <td>roman</td>\n",
       "      <td>-9.86</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>34.94</td>\n",
       "      <td>0</td>\n",
       "      <td>VWC</td>\n",
       "      <td>1390</td>\n",
       "      <td>109</td>\n",
       "      <td>12</td>\n",
       "      <td>long rain</td>\n",
       "      <td>0</td>\n",
       "      <td>Iringa-5</td>\n",
       "      <td>non-autonomous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>functional</td>\n",
       "      <td>grumeti</td>\n",
       "      <td>grumeti</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>34.70</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>1400</td>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>long rain</td>\n",
       "      <td>1</td>\n",
       "      <td>Mara-2</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>functional</td>\n",
       "      <td>other</td>\n",
       "      <td>world vision</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>37.46</td>\n",
       "      <td>1</td>\n",
       "      <td>VWC</td>\n",
       "      <td>690</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>short dry</td>\n",
       "      <td>0</td>\n",
       "      <td>Manyara-4</td>\n",
       "      <td>non-autonomous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>non functional</td>\n",
       "      <td>unicef</td>\n",
       "      <td>unicef</td>\n",
       "      <td>-11.16</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>38.49</td>\n",
       "      <td>1</td>\n",
       "      <td>VWC</td>\n",
       "      <td>260</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>short dry</td>\n",
       "      <td>1</td>\n",
       "      <td>Mtwara-63</td>\n",
       "      <td>non-autonomous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>functional</td>\n",
       "      <td>other</td>\n",
       "      <td>artisan</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>31.13</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>1330</td>\n",
       "      <td>532</td>\n",
       "      <td>15</td>\n",
       "      <td>long dry</td>\n",
       "      <td>1</td>\n",
       "      <td>Kagera-1</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group   funder     installer  latitude  \\\n",
       "0  69572      functional    roman         roman     -9.86   \n",
       "1   8776      functional  grumeti       grumeti     -2.15   \n",
       "2  34310      functional    other  world vision     -3.82   \n",
       "3  67743  non functional   unicef        unicef    -11.16   \n",
       "4  19728      functional    other       artisan     -1.83   \n",
       "\n",
       "                     basin region_code  public_meeting extraction_type  \\\n",
       "0               Lake Nyasa          11               1         gravity   \n",
       "1            Lake Victoria          20               1         gravity   \n",
       "2                  Pangani          21               1         gravity   \n",
       "3  Ruvuma / Southern Coast          90               1     submersible   \n",
       "4            Lake Victoria          18               1         gravity   \n",
       "\n",
       "  extraction_type_class payment_type water_quality      quantity  \\\n",
       "0               gravity     annually          soft        enough   \n",
       "1               gravity    never pay          soft  insufficient   \n",
       "2               gravity   per bucket          soft        enough   \n",
       "3           submersible    never pay          soft           dry   \n",
       "4               gravity    never pay          soft      seasonal   \n",
       "\n",
       "                 source              waterpoint_type  longitude  permit  \\\n",
       "0                spring           communal standpipe      34.94       0   \n",
       "1  rainwater harvesting           communal standpipe      34.70       1   \n",
       "2                   dam  communal standpipe multiple      37.46       1   \n",
       "3           machine dbh  communal standpipe multiple      38.49       1   \n",
       "4  rainwater harvesting           communal standpipe      31.13       1   \n",
       "\n",
       "  scheme_management  gps_height  population  age     season  \\\n",
       "0               VWC        1390         109   12  long rain   \n",
       "1             Other        1400         280    3  long rain   \n",
       "2               VWC         690         250    4  short dry   \n",
       "3               VWC         260          58   27  short dry   \n",
       "4             Other        1330         532   15   long dry   \n",
       "\n",
       "   amount_tsh_missing region_district authority_scheme  \n",
       "0                   0        Iringa-5   non-autonomous  \n",
       "1                   1          Mara-2            other  \n",
       "2                   0       Manyara-4   non-autonomous  \n",
       "3                   1       Mtwara-63   non-autonomous  \n",
       "4                   1        Kagera-1            other  "
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#during EDA I already decided what features to keep and which ones to drop\n",
    "train_df = train_df.drop(['amount_tsh', 'date_recorded', 'wpt_name', 'num_private', 'subvillage', 'region',  'district_code', 'lga', 'ward', 'recorded_by', 'scheme_name', 'extraction_type_group', 'management', 'management_group', 'payment', 'quality_group', 'quantity_group', 'source_class', 'source_type', 'waterpoint_type_group', 'construction_year'], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "df = train_df[train_df['status_group'].notnull()].copy()\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = df.drop('status_group', axis=1)\n",
    "y = df['status_group']\n",
    "\n",
    "# Identify the index of the 'functional_needs_repair' class\n",
    "repair_index = y[y == 'functional needs repair'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_cols = [col for col in X.columns if len(X[col].unique()) < 200]\n",
    "categorical_cols = [cname for cname in X .columns if\n",
    "                   X [cname].dtype == \"object\"]\n",
    "\n",
    "# Convert numerical columns to object type\n",
    "for col in categorical_cols:\n",
    "        X[col] = X[col].astype(object)\n",
    "\n",
    "# Create a categorical mask\n",
    "cat_mask = [True if col in categorical_cols else False for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE-NC to oversample the 'functional_needs_repair' class\n",
    "smotenc = SMOTENC(categorical_features=cat_mask, k_neighbors=5, random_state=42, sampling_strategy={'functional needs repair': 7000})\n",
    "X_resampled, y_resampled = smotenc.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62082 entries, 0 to 62081\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     62082 non-null  int64  \n",
      " 1   funder                 62082 non-null  object \n",
      " 2   installer              62082 non-null  object \n",
      " 3   latitude               62082 non-null  float64\n",
      " 4   basin                  62082 non-null  object \n",
      " 5   region_code            62082 non-null  object \n",
      " 6   public_meeting         62082 non-null  int64  \n",
      " 7   extraction_type        62082 non-null  object \n",
      " 8   extraction_type_class  62082 non-null  object \n",
      " 9   payment_type           62082 non-null  object \n",
      " 10  water_quality          62082 non-null  object \n",
      " 11  quantity               62082 non-null  object \n",
      " 12  source                 62082 non-null  object \n",
      " 13  waterpoint_type        62082 non-null  object \n",
      " 14  longitude              62082 non-null  float64\n",
      " 15  permit                 62082 non-null  int64  \n",
      " 16  scheme_management      62082 non-null  object \n",
      " 17  gps_height             62082 non-null  int64  \n",
      " 18  population             62082 non-null  int64  \n",
      " 19  age                    62082 non-null  int64  \n",
      " 20  season                 62082 non-null  object \n",
      " 21  amount_tsh_missing     62082 non-null  int64  \n",
      " 22  region_district        62082 non-null  object \n",
      " 23  authority_scheme       62082 non-null  object \n",
      " 24  status_group           62082 non-null  object \n",
      "dtypes: float64(2), int64(7), object(16)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with the resampled data\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_resampled['status_group'] = y_resampled\n",
    "\n",
    "df_resampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 74249 0.0 int64\n",
      "status_group 4 20.0 object\n",
      "funder 151 0.0 object\n",
      "installer 151 0.0 object\n",
      "latitude 1058 0.0 float64\n",
      "basin 9 0.0 object\n",
      "region_code 27 0.0 object\n",
      "public_meeting 2 0.0 int64\n",
      "extraction_type 16 0.0 object\n",
      "extraction_type_class 7 0.0 object\n",
      "payment_type 7 0.0 object\n",
      "water_quality 8 0.0 object\n",
      "quantity 5 0.0 object\n",
      "source 9 0.0 object\n",
      "waterpoint_type 7 0.0 object\n",
      "longitude 1074 0.0 float64\n",
      "permit 2 0.0 int64\n",
      "scheme_management 12 0.0 object\n",
      "gps_height 270 0.0 int64\n",
      "population 1138 0.0 int64\n",
      "age 60 0.0 int64\n",
      "season 4 0.0 object\n",
      "amount_tsh_missing 2 0.0 int64\n",
      "region_district 132 0.0 object\n",
      "authority_scheme 4 0.0 object\n"
     ]
    }
   ],
   "source": [
    "missing = round((train_df.isna().sum())/len(train_df)*100,1)\n",
    "missing = missing.sort_values(ascending = False)\n",
    "\n",
    "for col in train_df.columns:\n",
    "    print(col, len(train_df[col].unique()), missing[col], train_df[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sw_oversampling:\n",
    "    train_df = pd.concat([df_resampled, train_df[train_df['status_group'].isna()]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 74249 0.0 int64\n",
      "status_group 4 20.0 object\n",
      "funder 151 0.0 object\n",
      "installer 151 0.0 object\n",
      "latitude 1058 0.0 float64\n",
      "basin 9 0.0 object\n",
      "region_code 27 0.0 object\n",
      "public_meeting 2 0.0 int64\n",
      "extraction_type 16 0.0 object\n",
      "extraction_type_class 7 0.0 object\n",
      "payment_type 7 0.0 object\n",
      "water_quality 8 0.0 object\n",
      "quantity 5 0.0 object\n",
      "source 9 0.0 object\n",
      "waterpoint_type 7 0.0 object\n",
      "longitude 1074 0.0 float64\n",
      "permit 2 0.0 int64\n",
      "scheme_management 12 0.0 object\n",
      "gps_height 270 0.0 int64\n",
      "population 1138 0.0 int64\n",
      "age 60 0.0 int64\n",
      "season 4 0.0 object\n",
      "amount_tsh_missing 2 0.0 int64\n",
      "region_district 132 0.0 object\n",
      "authority_scheme 4 0.0 object\n"
     ]
    }
   ],
   "source": [
    "missing = round((train_df.isna().sum())/len(train_df)*100,1)\n",
    "missing = missing.sort_values(ascending = False)\n",
    "\n",
    "for col in train_df.columns:\n",
    "    print(col, len(train_df[col].unique()), missing[col], train_df[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74249 entries, 0 to 74248\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     74249 non-null  int64  \n",
      " 1   status_group           59399 non-null  object \n",
      " 2   funder                 74249 non-null  object \n",
      " 3   installer              74249 non-null  object \n",
      " 4   latitude               74249 non-null  float64\n",
      " 5   basin                  74249 non-null  object \n",
      " 6   region_code            74249 non-null  object \n",
      " 7   public_meeting         74249 non-null  int64  \n",
      " 8   extraction_type        74249 non-null  object \n",
      " 9   extraction_type_class  74249 non-null  object \n",
      " 10  payment_type           74249 non-null  object \n",
      " 11  water_quality          74249 non-null  object \n",
      " 12  quantity               74249 non-null  object \n",
      " 13  source                 74249 non-null  object \n",
      " 14  waterpoint_type        74249 non-null  object \n",
      " 15  longitude              74249 non-null  float64\n",
      " 16  permit                 74249 non-null  int64  \n",
      " 17  scheme_management      74249 non-null  object \n",
      " 18  gps_height             74249 non-null  int64  \n",
      " 19  population             74249 non-null  int64  \n",
      " 20  age                    74249 non-null  int64  \n",
      " 21  season                 74249 non-null  object \n",
      " 22  amount_tsh_missing     74249 non-null  int64  \n",
      " 23  region_district        74249 non-null  object \n",
      " 24  authority_scheme       74249 non-null  object \n",
      "dtypes: float64(2), int64(7), object(16)\n",
      "memory usage: 14.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define train and test \n",
    "# train_set = train_df[train_df [\"id\"].isin(train_base_df[\"id\"])]\n",
    "# test_set =  train_df[train_df  [\"id\"].isin(test_df[\"id\"])]\n",
    "\n",
    "train_set = train_df[train_df['status_group'].notna()]\n",
    "test_set =  train_df[train_df['status_group'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop(['id', 'status_group'], axis=1)\n",
    "y = train_set['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funder', 'installer', 'latitude', 'basin', 'region_code',\n",
       "       'public_meeting', 'extraction_type', 'extraction_type_class',\n",
       "       'payment_type', 'water_quality', 'quantity', 'source',\n",
       "       'waterpoint_type', 'longitude', 'permit', 'scheme_management',\n",
       "       'gps_height', 'population', 'age', 'season', 'amount_tsh_missing',\n",
       "       'region_district', 'authority_scheme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [cname for cname in X .columns if\n",
    "                   X [cname].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Columns \n",
    "for col in categorical_cols:\n",
    "  le = LabelEncoder()\n",
    "  train_set[col] = le.fit_transform(train_set[col])\n",
    "  test_set[col] = le.transform(test_set[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the encoded train and test sets together\n",
    "train_df = train_set.append(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'status_group', 'funder', 'installer', 'latitude', 'basin',\n",
       "       'region_code', 'public_meeting', 'extraction_type',\n",
       "       'extraction_type_class', 'payment_type', 'water_quality', 'quantity',\n",
       "       'source', 'waterpoint_type', 'longitude', 'permit', 'scheme_management',\n",
       "       'gps_height', 'population', 'age', 'season', 'amount_tsh_missing',\n",
       "       'region_district', 'authority_scheme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status_group          20.0\n",
       "id                     0.0\n",
       "source                 0.0\n",
       "region_district        0.0\n",
       "amount_tsh_missing     0.0\n",
       "season                 0.0\n",
       "age                    0.0\n",
       "population             0.0\n",
       "gps_height             0.0\n",
       "scheme_management      0.0\n",
       "permit                 0.0\n",
       "longitude              0.0\n",
       "waterpoint_type        0.0\n",
       "quantity               0.0\n",
       "water_quality          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = round((train_df.isna().sum())/len(train_df)*100,1)\n",
    "missing = missing.sort_values(ascending = False)\n",
    "missing.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#machine learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train and test \n",
    "train_set = train_df[train_df['status_group'].notna()]\n",
    "test_set = train_df[train_df['status_group'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y for training the model\n",
    "X= train_set.drop(['id', 'status_group'], axis=1)\n",
    "y = train_set['status_group']\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42 , stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- FOR 100 ESTIMATORS -------\n",
      "Accuracy score (train): 0.9548\n",
      "Accuracy score (test): 0.8146\n",
      "Precision score (train): 0.9552\n",
      "Precision score (test): 0.8079\n",
      "Recall score (train): 0.9548\n",
      "Recall score (test): 0.8146\n",
      "F1 score (train): 0.9542\n",
      "F1 score (test): 0.8063\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.90      0.85      6452\n",
      "functional needs repair       0.58      0.30      0.40       863\n",
      "         non functional       0.85      0.79      0.82      4565\n",
      "\n",
      "               accuracy                           0.81     11880\n",
      "              macro avg       0.75      0.66      0.69     11880\n",
      "           weighted avg       0.81      0.81      0.81     11880\n",
      "\n",
      "------- FOR 200 ESTIMATORS -------\n",
      "Accuracy score (train): 0.9724\n",
      "Accuracy score (test): 0.8125\n",
      "Precision score (train): 0.9724\n",
      "Precision score (test): 0.8055\n",
      "Recall score (train): 0.9724\n",
      "Recall score (test): 0.8125\n",
      "F1 score (train): 0.9722\n",
      "F1 score (test): 0.8055\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.89      0.85      6452\n",
      "functional needs repair       0.56      0.33      0.41       863\n",
      "         non functional       0.84      0.79      0.82      4565\n",
      "\n",
      "               accuracy                           0.81     11880\n",
      "              macro avg       0.74      0.67      0.69     11880\n",
      "           weighted avg       0.81      0.81      0.81     11880\n",
      "\n",
      "------- FOR 300 ESTIMATORS -------\n",
      "Accuracy score (train): 0.9786\n",
      "Accuracy score (test): 0.8091\n",
      "Precision score (train): 0.9785\n",
      "Precision score (test): 0.8016\n",
      "Recall score (train): 0.9786\n",
      "Recall score (test): 0.8091\n",
      "F1 score (train): 0.9785\n",
      "F1 score (test): 0.8026\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.88      0.85      6452\n",
      "functional needs repair       0.53      0.33      0.40       863\n",
      "         non functional       0.84      0.80      0.82      4565\n",
      "\n",
      "               accuracy                           0.81     11880\n",
      "              macro avg       0.73      0.67      0.69     11880\n",
      "           weighted avg       0.80      0.81      0.80     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_est in [100, 200, 300, 400, 500]:\n",
    "\n",
    "    xgb1 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 42)\n",
    "    xgb2 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 2) \n",
    "    xgb3 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 142) \n",
    "    xgb4 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 33 )\n",
    "    xgb5 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 678)\n",
    "    xgb6 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 53)\n",
    "    xgb7 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 23)\n",
    "    xgb8 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 63)\n",
    "    xgb9 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 342)\n",
    "    xgb10 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 634)\n",
    "    xgb11 = XGBClassifier(max_depth =14, n_estimators= n_est, colsample_bytree = 0.4, eta = 0.2, random_state = 5)\n",
    "\n",
    "    # Create training and test sets: test size 0.2\n",
    "    X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "    vc = VotingClassifier([('xgb1', xgb1), ('xgb2', xgb2), ('xgb3', xgb3), ('xgb4', xgb4), ('xgb5', xgb5), ('xgb6', xgb6), ('xgb7', xgb7), ('xgb8', xgb8), ('xgb9', xgb9), ('xgb10', xgb10), ('xgb11', xgb11)], voting = 'soft')\n",
    "                        \n",
    "\n",
    "    #fit and predict\n",
    "    vc.fit(X_train , y_train)\n",
    "    pred= vc .predict(X_test)\n",
    "    pred_train = vc .predict(X_train)\n",
    "\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    accuracy_train = accuracy_score(y_train, pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, pred)\n",
    "\n",
    "    # Calculate precision scores\n",
    "    precision_train = precision_score(y_train, pred_train, average='weighted')\n",
    "    precision_test = precision_score(y_test, pred, average='weighted')\n",
    "\n",
    "    # Calculate recall scores\n",
    "    recall_train = recall_score(y_train, pred_train, average='weighted')\n",
    "    recall_test = recall_score(y_test, pred, average='weighted')\n",
    "\n",
    "    # Calculate F1 scores\n",
    "    f1_train = f1_score(y_train, pred_train, average='weighted')\n",
    "    f1_test = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "    # Print the scores\n",
    "    print(\"------- FOR\", n_est, \"ESTIMATORS -------\")\n",
    "\n",
    "    print(\"Accuracy score (train): {:.4f}\".format(accuracy_train))\n",
    "    print(\"Accuracy score (test): {:.4f}\".format(accuracy_test))\n",
    "    print(\"Precision score (train): {:.4f}\".format(precision_train))\n",
    "    print(\"Precision score (test): {:.4f}\".format(precision_test))\n",
    "    print(\"Recall score (train): {:.4f}\".format(recall_train))\n",
    "    print(\"Recall score (test): {:.4f}\".format(recall_test))\n",
    "    print(\"F1 score (train): {:.4f}\".format(f1_train))\n",
    "    print(\"F1 score (test): {:.4f}\".format(f1_test))\n",
    "\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "    # #heatmap\n",
    "    # fig, ax = plt.subplots(figsize=(8,5)) \n",
    "    # data = confusion_matrix(y_test, pred)\n",
    "    # df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "    # ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
    "    # ax.set_xlabel(\"Predicted\")\n",
    "    # ax.set_ylabel (\"Actual\")\n",
    "    # ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "    # ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(max_depth=30, max_features='log2', min_samples_split=7, n_estimators=225, random_state=42, warm_start=True)\n",
    "# xgb = XGBClassifier(max_depth =12, n_estimators= 200, colsample_bytree = 0.3, eta = 0.2, random_state = 42) \n",
    "# cat = CatBoostClassifier(max_depth = 9, rsm = 0.2, iterations = 1000, random_state = 42)\n",
    "# bag = BaggingClassifier(max_features=0.4, n_estimators=1000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training and test sets: test size 0.2\n",
    "# X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # vc = VotingClassifier([('rf', rf), ('xgb', xgb),('cat', cat), ('bag', bag)], voting = 'soft', weights = [0.861, 0.78, 0.706, 0.751])\n",
    "# vc = VotingClassifier([('rf', rf), ('xgb', xgb),('cat', cat), ('bag', bag)], voting = 'soft', weights = [0.85, 1, 0.85, 0.75])\n",
    "\n",
    "# #fit and predict\n",
    "# vc.fit(X_train , y_train)\n",
    "# pred= vc .predict(X_test)\n",
    "# pred_train = vc .predict(X_train)\n",
    "\n",
    "# # Calculate accuracy scores\n",
    "# accuracy_train = accuracy_score(y_train, pred_train)\n",
    "# accuracy_test = accuracy_score(y_test, pred)\n",
    "\n",
    "# # Calculate precision scores\n",
    "# precision_train = precision_score(y_train, pred_train, average='weighted')\n",
    "# precision_test = precision_score(y_test, pred, average='weighted')\n",
    "\n",
    "# # Calculate recall scores\n",
    "# recall_train = recall_score(y_train, pred_train, average='weighted')\n",
    "# recall_test = recall_score(y_test, pred, average='weighted')\n",
    "\n",
    "# # Calculate F1 scores\n",
    "# f1_train = f1_score(y_train, pred_train, average='weighted')\n",
    "# f1_test = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "# # Print the scores\n",
    "# print(\"Accuracy score (train): {:.4f}\".format(accuracy_train))\n",
    "# print(\"Accuracy score (test): {:.4f}\".format(accuracy_test))\n",
    "# print(\"Precision score (train): {:.4f}\".format(precision_train))\n",
    "# print(\"Precision score (test): {:.4f}\".format(precision_test))\n",
    "# print(\"Recall score (train): {:.4f}\".format(recall_train))\n",
    "# print(\"Recall score (test): {:.4f}\".format(recall_test))\n",
    "# print(\"F1 score (train): {:.4f}\".format(f1_train))\n",
    "# print(\"F1 score (test): {:.4f}\".format(f1_test))\n",
    "\n",
    "\n",
    "# #print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, pred))\n",
    "\n",
    "# #heatmap\n",
    "# fig, ax = plt.subplots(figsize=(8,5)) \n",
    "# data = confusion_matrix(y_test, pred)\n",
    "# df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "# ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
    "# ax.set_xlabel(\"Predicted\")\n",
    "# ax.set_ylabel (\"Actual\")\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "# ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MAKE ENSEMBLE OF 11 XGBOOSTS\n",
    "\n",
    "# #Create data frame to hold the 11 solutions developed by the model\n",
    "# solution.table<-data.frame(id=data_test[,\"id\"])\n",
    "# for (i in 2:12){\n",
    "#   #Set seed so that the results are reproducible\n",
    "#   set.seed(i)\n",
    "\n",
    "# #Cross validation to determine the number of iterations to run the model.\n",
    "# #I tested this model with a variety of parameters to find the most accurate model\n",
    "# xgb.tab = xgb.cv(data = train.DMatrix, objective = \"multi:softmax\", booster = \"gbtree\",\n",
    "#                  nrounds = 500, nfold = 4, early.stop.round = 10, num_class = 4, maximize = FALSE,\n",
    "#                  evaluation = \"merror\", eta = .2, max_depth = 12, colsample_bytree = .4)\n",
    "\n",
    "# #Create variable that identifies the optimal number of iterations for the model\n",
    "# min.error.idx = which.min(xgb.tab[, test.merror.mean])\n",
    "\n",
    "# #Create model using the same parameters used in xgb.cv\n",
    "# model <- xgboost(data = train.DMatrix, objective = \"multi:softmax\", booster = \"gbtree\",\n",
    "#                  eval_metric = \"merror\", nrounds = min.error.idx, \n",
    "#                  num_class = 4,eta = .2, max_depth = 14, colsample_bytree = .4)\n",
    "\n",
    "# #Predict. Used the data_test.noID because it contained the same number of columns as the train.DMatrix\n",
    "# #used to build the model.\n",
    "# predict <- predict(model,data_test.noID)\n",
    "\n",
    "# #Modify prediction labels to match submission format\n",
    "# predict[predict==1]<-\"functional\"\n",
    "# predict[predict==2]<-\"functional needs repair\"\n",
    "# predict[predict==3]<-\"non functional\"\n",
    "\n",
    "# #View prediction\n",
    "# table(predict)\n",
    "\n",
    "# #Add the solution to column i of the solutions data frame. This creates a data frame with a column for\n",
    "# #each prediction set. Each prediction is a vote for that prediction. Next I will count the number of votes\n",
    "# #for each prediction as use the element with the most votes as my final solution.\n",
    "# solution.table[,i]<-predict\n",
    "# }\n",
    "\n",
    "# #Count the number of votes for each solution for each row\n",
    "# solution.table.count<-apply(solution.table,MARGIN=1,table)\n",
    "\n",
    "# #Create a vector to hold the final solution\n",
    "# predict.combined<-vector()\n",
    "\n",
    "# x=1\n",
    "# #Finds the element that has the most votes for each prediction row\n",
    "# for (x in 1:nrow(data_test)){\n",
    "#   predict.combined[x]<-names(which.max(solution.table.count[[x]]))}\n",
    "\n",
    "# #View the number of predictions for each classification\n",
    "# table(predict.combined)\n",
    "\n",
    "# #Create solution data frame\n",
    "# solution<- data.frame(id=data_test[,\"id\"], status_group=predict.combined)\n",
    "\n",
    "# #View the first five rows of the solution to ensure that it follows submission format rules\n",
    "# head(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fit on foll training set\n",
    "# vc.fit(X , y)\n",
    "\n",
    "# #predict\n",
    "# submission = test_set.drop(['id', 'status_group'], axis=1)\n",
    "# submission['status_group'] = vc.predict(submission)\n",
    "\n",
    "# #bring the id column back\n",
    "# submission['id'] = test_set['id']\n",
    "\n",
    "# #create df for submission and save\n",
    "# best_submission = submission[['id', 'status_group']]\n",
    "# best_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_submission.to_csv('best_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
