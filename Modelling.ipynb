{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Models used by BrendaLoznik:\n",
    "- `RandomForestClassifier`\n",
    "- `XGBClassifier`\n",
    "- `CatBoostClassifier`\n",
    "- `BaggingClassifier`\n",
    "- `StackingClassifier`\n",
    "- Weighted Vote\n",
    "- SHAP (SHapley Additive exPlanations) with `TreeExplainer`\n",
    "\n",
    "### **Our contribution**\n",
    "\n",
    "Hyperparameter tuning for `XGBClassifier` and weights tuning for Weighted Vote\n",
    "\n",
    "Implementing new models:\n",
    "- `LGBMClassifier`\n",
    "- `GradientBoostingClassifier`\n",
    "- `AdaBoostClassifier`\n",
    "- `ExtraTreesClassifier`\n",
    "- `MLPClassifier`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#machine learning\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vg/953jt4190_x2bp1n7tcvzfpr0000gn/T/ipykernel_26601/3498357959.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_set = pd.read_csv(\"final_df.csv\")\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"final_df.csv\")\n",
    "train_set = train_set.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set[train_set['status_group'].notna()]\n",
    "test_set = train_set[train_set['status_group'].isna()]\n",
    "\n",
    "#define X and y for training the model\n",
    "X= train_set.drop(['id', 'status_group'], axis=1)\n",
    "y = train_set['status_group']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42 , stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest params tuning\n",
    "\n",
    "Performed by BrendaLoznik with the following results:\n",
    "- `max_depth`: 30\n",
    "- `max_features`: 'log2'\n",
    "- `min_samples_split`: 8\n",
    "- `n_estimators`: 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=30, max_features='log2', min_samples_split=8, n_estimators=150, random_state=42, warm_start=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training and test sets: test size 0.2\n",
    "# X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "# param_grid = { \n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'colsample_bytree' :[ 0.3, 0.4, 0.5],\n",
    "#     'eta': [0.15, 0.2, 0.3],\n",
    "#     'max_depth': [10, 11, 12, 13, 14, 15]\n",
    "#     }\n",
    "\n",
    "# #Create a based model\n",
    "# xgb = XGBClassifier( random_state=42)\n",
    "\n",
    "# grid_search_xgb = GridSearchCV(estimator = xgb, param_grid = param_grid, cv = 5,  verbose = 2,  scoring = 'accuracy')\n",
    "\n",
    "# #fitmodel\n",
    "# grid_search_xgb.fit(X_train, y_train,  eval_metric = 'mlogloss',)\n",
    "\n",
    "# #print best parameters \n",
    "# print('Best Score:', grid_search_xgb.best_score_)\n",
    "# print('Parameters:', grid_search_xgb.best_params_)\n",
    "# print('Best Model:', grid_search_xgb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Score: 0.8103495737302167\n",
    "# Parameters: {'colsample_bytree': 0.3, 'eta': 0.15, 'max_depth': 12, 'n_estimators': 100}\n",
    "# Best Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "#               colsample_bylevel=None, colsample_bynode=None,\n",
    "#               colsample_bytree=0.3, early_stopping_rounds=None,\n",
    "#               enable_categorical=False, eta=0.15, eval_metric=None,\n",
    "#               feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
    "#               importance_type=None, interaction_constraints=None,\n",
    "#               learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
    "#               max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n",
    "#               max_leaves=None, min_child_weight=None, missing=nan,\n",
    "#               monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
    "#               num_parallel_tree=None, objective='multi:softprob', ...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (train): 0.9305\n",
      "Accuracy score (test): 0.8152\n",
      "Precision score (train): 0.9323\n",
      "Precision score (test): 0.8115\n",
      "Recall score (train): 0.9305\n",
      "Recall score (test): 0.8152\n",
      "F1 score (train): 0.9284\n",
      "F1 score (test): 0.8044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85      6452\n",
      "           1       0.65      0.27      0.38       863\n",
      "           2       0.86      0.78      0.82      4565\n",
      "\n",
      "    accuracy                           0.82     11880\n",
      "   macro avg       0.77      0.65      0.68     11880\n",
      "weighted avg       0.81      0.82      0.80     11880\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 100 estimators turns out to be the best\n",
    "\n",
    "xgb1 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 42)\n",
    "xgb2 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 2) \n",
    "xgb3 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 142) \n",
    "xgb4 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 33 )\n",
    "xgb5 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 678)\n",
    "xgb6 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 53)\n",
    "xgb7 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 23)\n",
    "xgb8 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 63)\n",
    "xgb9 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 342)\n",
    "xgb10 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 634)\n",
    "xgb11 = XGBClassifier(max_depth =12, n_estimators= 100, colsample_bytree = 0.3, eta = 0.15, random_state = 5)\n",
    "\n",
    "# Create training and test sets: test size 0.2\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "vc = VotingClassifier([('xgb1', xgb1), ('xgb2', xgb2), ('xgb3', xgb3), ('xgb4', xgb4), ('xgb5', xgb5), ('xgb6', xgb6), ('xgb7', xgb7), ('xgb8', xgb8), ('xgb9', xgb9), ('xgb10', xgb10), ('xgb11', xgb11)], voting = 'soft')       \n",
    "\n",
    "#fit and predict\n",
    "vc.fit(X_train , y_train)\n",
    "pred= vc .predict(X_test)\n",
    "pred_train = vc .predict(X_train)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "accuracy_train = accuracy_score(y_train, pred_train)\n",
    "accuracy_test = accuracy_score(y_test, pred)\n",
    "\n",
    "# Calculate precision scores\n",
    "precision_train = precision_score(y_train, pred_train, average='weighted')\n",
    "precision_test = precision_score(y_test, pred, average='weighted')\n",
    "\n",
    "# Calculate recall scores\n",
    "recall_train = recall_score(y_train, pred_train, average='weighted')\n",
    "recall_test = recall_score(y_test, pred, average='weighted')\n",
    "\n",
    "# Calculate F1 scores\n",
    "f1_train = f1_score(y_train, pred_train, average='weighted')\n",
    "f1_test = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy score (train): {:.4f}\".format(accuracy_train))\n",
    "print(\"Accuracy score (test): {:.4f}\".format(accuracy_test))\n",
    "print(\"Precision score (train): {:.4f}\".format(precision_train))\n",
    "print(\"Precision score (test): {:.4f}\".format(precision_test))\n",
    "print(\"Recall score (train): {:.4f}\".format(recall_train))\n",
    "print(\"Recall score (test): {:.4f}\".format(recall_test))\n",
    "print(\"F1 score (train): {:.4f}\".format(f1_train))\n",
    "print(\"F1 score (test): {:.4f}\".format(f1_test))\n",
    "\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "#heatmap\n",
    "fig, ax = plt.subplots(figsize=(8,5)) \n",
    "data = confusion_matrix(y_test, pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel (\"Actual\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost\n",
    "\n",
    "Performed by BrendaLoznik with the following results:\n",
    "- `rsm`: 0.2\n",
    "- `max_depth`: '9'\n",
    "- `iterations`: 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(rsm=0.2, max_depth=9, iterations=1000, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier\n",
    "\n",
    "Performed by BrendaLoznik with the following results:\n",
    "- `n_estimators`: 1000\n",
    "- `max_features`: '0.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = BaggingClassifier( random_state=42, n_estimators = 1000, max_features = 0.4 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=30, max_features='log2', min_samples_split=7, n_estimators=225, random_state=42, warm_start=True)\n",
    "xgb = XGBClassifier(max_depth =12, n_estimators= 200, colsample_bytree = 0.3, eta = 0.2, random_state = 42) \n",
    "cat = CatBoostClassifier(max_depth = 9, rsm = 0.2, iterations = 1000, random_state = 42)\n",
    "bag = BaggingClassifier(max_features=0.4, n_estimators=1000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Create training and test sets: test size 0.2\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "best_weights = [0, 0, 0, 0]\n",
    "best_acc = 0.0\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    i+=1\n",
    "\n",
    "    w = [round(random.uniform(0.3, 1.0), 3), round(random.uniform(0.3, 1.0), 3), round(random.uniform(0.3, 1.0), 3), round(random.uniform(0.3, 1.0), 3)]\n",
    "\n",
    "    vc = VotingClassifier([('rf', rf), ('xgb', xgb),('cat', cat), ('bag', bag)], voting = 'soft', weights = w)         \n",
    "\n",
    "    #fit and predict\n",
    "    vc.fit(X_train , y_train)\n",
    "    pred= vc .predict(X_test)\n",
    "    pred_train = vc .predict(X_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "\n",
    "    #print best model scores on test data\n",
    "    print(\"Accuracy score train: {}\".format(accuracy_score(y_train ,pred_train)))\n",
    "    print(\"Accuracy score test: {}\".format(acc))\n",
    "    print(\"Weights:\", w)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_weights = w\n",
    "\n",
    "    print(\"Best weights:\", best_weights, \"with result:\", best_acc)\n",
    "\n",
    "    # open the file in write mode\n",
    "    with open('output.txt', 'a') as f:\n",
    "        # print best model scores on test data to file\n",
    "        f.write(\"\\nIteration: {}\\n\".format(i))\n",
    "        f.write(\"Accuracy score train: {}\\n\".format(accuracy_score(y_train, pred_train)))\n",
    "        f.write(\"Accuracy score test: {}\\n\".format(acc))\n",
    "        f.write(\"Weights: {}\\n\".format(w))\n",
    "        f.write(\"Best weights: {} with result: {}\\n\".format(best_weights, best_acc))\n",
    "\n",
    "\n",
    "# Best weights: [0.861, 0.78, 0.706, 0.751] with "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best weights found are [0.861, 0.78, 0.706, 0.751] with accuracy 0.8175925925925925 after 211 iterations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets: test size 0.2\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('cat', cat), ('bag', bag)],\n",
    "    final_estimator=LogisticRegression()\n",
    "    )\n",
    "                       \n",
    "\n",
    "#fit and predict\n",
    "stack.fit(X_train , y_train)\n",
    "pred= stack.predict(X_test)\n",
    "pred_train = stack.predict(X_train)\n",
    "\n",
    "\n",
    "#print best model scores on test data\n",
    "print(\"Accuracy score train: {}\".format(accuracy_score(y_train ,pred_train)))\n",
    "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, pred)))\n",
    "\n",
    "\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "#heatmap\n",
    "fig, ax = plt.subplots(figsize=(8,5)) \n",
    "data = confusion_matrix(y_test, pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel (\"Actual\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "Solution by BrendaLoznik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=train_set.copy()\n",
    "\n",
    "#calcualte how many samples of each status group I need\n",
    "required_samples = len(df)*0.4  #40%\n",
    "functional_samples = round(required_samples* 0.543081)\n",
    "non_functional_samples = round(required_samples * 0.384242)\n",
    "repair_samples = round(required_samples * 0.072677)\n",
    "\n",
    "#create sepperate df for each status group\n",
    "functional = df[df['status_group']=='functional']\n",
    "non_functional = df[df['status_group']=='non functional']\n",
    "repair = df[df['status_group']=='functional needs repair']\n",
    "\n",
    "#create a random sample of each rstatus group\n",
    "sample_functional = functional.sample(n = functional_samples, random_state=1, )\n",
    "sample_non_functional = non_functional.sample(n = non_functional_samples, random_state=1, )\n",
    "sample_repair = repair.sample(n = repair_samples, random_state=1, )\n",
    "\n",
    "#combine the random samples to a single df\n",
    "sample = sample_functional.append(sample_non_functional)\n",
    "sample = sample.append(sample_repair)\n",
    "\n",
    "#define X and y for training the model\n",
    "X= sample.drop(['id', 'status_group'], axis=1)\n",
    "y = sample['status_group']\n",
    "\n",
    "#define and fit the model\n",
    "rf = RandomForestClassifier(max_depth=30, max_features='log2', min_samples_split=7, n_estimators=225, random_state=42, warm_start=True)\n",
    "rf.fit(X, y)\n",
    "\n",
    "#calculate SHAP\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values_train = explainer.shap_values(X)\n",
    "\n",
    "#plot SHAP\n",
    "shap.summary_plot(shap_values_train, X_train.values, plot_type=\"bar\",  feature_names = X.columns)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets: test size 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "param_grid_lgbm = {\n",
    "    'max_depth': [7, 8, 9],\n",
    "    'num_iterations': [1000, 750],\n",
    "    'bagging_fraction': [0.3, 0.2]\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "grid_search_lgbm = GridSearchCV(estimator=lgbm, param_grid=param_grid_lgbm, cv=5, verbose=2, scoring='accuracy')\n",
    "grid_search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "print('LightGBM - Best Score:', grid_search_lgbm.best_score_)\n",
    "print('LightGBM - Best Parameters:', grid_search_lgbm.best_params_)\n",
    "print('LightGBM - Best Model:', grid_search_lgbm.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'max_depth': [7, 8, 9],\n",
    "    'n_estimators': [1000, 750],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "grid_search_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5, verbose=2, scoring='accuracy')\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "print('Gradient Boosting - Best Score:', grid_search_gb.best_score_)\n",
    "print('Gradient Boosting - Best Parameters:', grid_search_gb.best_params_)\n",
    "print('Gradient Boosting - Best Model:', grid_search_gb.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing model\n",
    "# gb = GradientBoostingClassifier(max_depth=, n_estimators=, learning_rate=, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   2.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   2.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   2.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   2.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   2.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   5.7s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   5.7s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   5.6s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   5.6s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   5.6s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=   8.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=   8.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=   8.7s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=   8.5s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=300; total time=   8.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   2.9s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   2.9s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   5.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   5.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   5.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   5.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   5.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=   8.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=   8.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=   8.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=   8.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=300; total time=   8.8s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   2.8s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   2.9s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   2.9s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   2.9s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   2.9s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   5.8s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   5.6s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   5.7s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   5.9s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   5.7s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=300; total time=  10.9s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=300; total time=   9.1s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=300; total time=   9.1s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=300; total time=   8.6s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=300; total time=   8.6s\n",
      "AdaBoost - Best Score: 0.7343167659087632\n",
      "AdaBoost - Best Parameters: {'learning_rate': 0.1, 'n_estimators': 300}\n",
      "AdaBoost - Best Model: AdaBoostClassifier(learning_rate=0.1, n_estimators=300, random_state=42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "grid_search_ada = GridSearchCV(estimator=ada, param_grid=param_grid_ada, cv=5, verbose=2, scoring='accuracy')\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "\n",
    "print('AdaBoost - Best Score:', grid_search_ada.best_score_)\n",
    "print('AdaBoost - Best Parameters:', grid_search_ada.best_params_)\n",
    "print('AdaBoost - Best Model:', grid_search_ada.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost - Best Score: 0.7343167659087632\n",
    "\n",
    "AdaBoost - Best Parameters: {'learning_rate': 0.1, 'n_estimators': 300}\n",
    "\n",
    "AdaBoost - Best Model: AdaBoostClassifier(learning_rate=0.1, n_estimators=300, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing model\n",
    "ada = AdaBoostClassifier(n_estimators=300, learning_rate=0.1, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=300; total time=   3.0s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=300; total time=   3.1s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=300; total time=   3.0s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=300; total time=   3.0s\n",
      "[CV] END .max_depth=7, min_samples_split=2, n_estimators=300; total time=   3.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=200; total time=   2.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=200; total time=   2.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=200; total time=   2.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=200; total time=   2.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=200; total time=   2.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=300; total time=   3.1s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=300; total time=   3.2s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=300; total time=   3.0s\n",
      "[CV] END .max_depth=7, min_samples_split=4, n_estimators=300; total time=   3.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=100; total time=   1.0s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=200; total time=   2.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=200; total time=   2.0s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=200; total time=   2.0s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=200; total time=   2.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=200; total time=   2.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=300; total time=   3.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=300; total time=   3.0s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=300; total time=   3.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=300; total time=   3.1s\n",
      "[CV] END .max_depth=7, min_samples_split=6, n_estimators=300; total time=   3.1s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=300; total time=   3.5s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=300; total time=   3.4s\n",
      "[CV] END .max_depth=8, min_samples_split=2, n_estimators=300; total time=   3.4s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=200; total time=   2.2s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=4, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=100; total time=   1.1s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=200; total time=   2.4s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=200; total time=   2.3s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=200; total time=   2.3s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=200; total time=   2.3s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=200; total time=   2.3s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=300; total time=   3.4s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=300; total time=   3.3s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=300; total time=   3.4s\n",
      "[CV] END .max_depth=8, min_samples_split=6, n_estimators=300; total time=   3.4s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END .max_depth=9, min_samples_split=2, n_estimators=300; total time=   3.9s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=100; total time=   1.4s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=100; total time=   1.4s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=100; total time=   1.3s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=100; total time=   1.3s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=100; total time=   1.4s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=200; total time=   2.6s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=200; total time=   2.4s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=200; total time=   2.5s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=200; total time=   2.5s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=200; total time=   2.5s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=300; total time=   3.8s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=300; total time=   3.7s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=300; total time=   3.7s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=300; total time=   3.8s\n",
      "[CV] END .max_depth=9, min_samples_split=4, n_estimators=300; total time=   3.8s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=100; total time=   1.2s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=200; total time=   2.5s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=200; total time=   2.4s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=200; total time=   2.4s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=200; total time=   2.4s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=200; total time=   2.4s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=300; total time=   3.7s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=300; total time=   3.7s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=300; total time=   3.6s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=300; total time=   3.6s\n",
      "[CV] END .max_depth=9, min_samples_split=6, n_estimators=300; total time=   3.6s\n",
      "Extra Trees Classifier - Best Score: 0.7503104017125904\n",
      "Extra Trees Classifier - Best Parameters: {'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "Extra Trees Classifier - Best Model: ExtraTreesClassifier(max_depth=9, min_samples_split=4, n_estimators=200,\n",
      "                     random_state=42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "param_grid_etc = {\n",
    "    'max_depth': [7, 8, 9],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "etc = ExtraTreesClassifier(random_state=42)\n",
    "grid_search_etc = GridSearchCV(estimator=etc, param_grid=param_grid_etc, cv=5, verbose=2, scoring='accuracy')\n",
    "grid_search_etc.fit(X_train, y_train)\n",
    "\n",
    "print('Extra Trees Classifier - Best Score:', grid_search_etc.best_score_)\n",
    "print('Extra Trees Classifier - Best Parameters:', grid_search_etc.best_params_)\n",
    "print('Extra Trees Classifier - Best Model:', grid_search_etc.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees Classifier - Best Score: 0.7503104017125904\n",
    "\n",
    "Extra Trees Classifier - Best Parameters: {'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 200}\n",
    "\n",
    "Extra Trees Classifier - Best Model: ExtraTreesClassifier(max_depth=9, min_samples_split=4, n_estimators=200,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing model\n",
    "etc = ExtraTreesClassifier(max_depth=0, n_estimators=200, min_samples_split=4, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   7.4s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   5.6s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   7.1s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.1s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   6.6s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   5.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   5.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   5.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   5.8s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   6.1s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.6s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   8.9s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   5.0s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  26.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  23.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  22.3s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=  13.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=   7.8s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=   7.4s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=   7.3s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=   7.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=  12.7s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=  10.4s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=  17.6s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=  27.1s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=  22.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=  19.7s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=   9.9s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=   7.2s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=   8.1s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  32.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  35.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  30.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  22.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  28.0s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  36.4s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  51.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  47.2s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  36.9s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  42.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=  22.9s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=  44.8s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   5.0s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   8.4s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=  11.8s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  31.4s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  49.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  53.8s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  39.5s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  44.3s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  35.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  44.2s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  20.3s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  33.1s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  24.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=  25.4s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=  10.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=  28.8s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=  18.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=  18.2s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   7.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   6.8s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   5.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=   7.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=constant, solver=sgd; total time=  12.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=  25.6s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   9.7s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=  28.5s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=  17.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=  24.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  29.4s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  24.9s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  26.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=sgd; total time=  27.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=  30.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=  46.6s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=  33.4s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=  19.4s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=adam; total time=  19.5s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=   5.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=   6.8s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=   6.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=constant, solver=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=  28.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=  38.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=  28.8s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=  22.7s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=adam; total time=  21.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  23.9s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  16.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  14.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  16.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(50, 50), learning_rate=adaptive, solver=sgd; total time=  13.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  22.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  44.5s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  42.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  47.6s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=adam; total time=  31.4s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   5.4s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   9.8s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=  10.6s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   5.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=constant, solver=sgd; total time=   9.8s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  21.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  41.5s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  45.2s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  48.5s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=adam; total time=  30.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time= 1.2min\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  53.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  50.4s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  41.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/miniconda3/envs/dsml/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, hidden_layer_sizes=(100, 50), learning_rate=adaptive, solver=sgd; total time=  57.0s\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks\n",
    "param_grid_nn = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "nn = MLPClassifier(random_state=42)\n",
    "grid_search_nn = GridSearchCV(estimator=nn, param_grid=param_grid_nn, cv=5, verbose=2, scoring='accuracy')\n",
    "grid_search_nn.fit(X_train, y_train)\n",
    "\n",
    "print('Neural Networks - Best Score:', grid_search_nn.best_score_)\n",
    "print('Neural Networks - Best Parameters:', grid_search_nn.best_params_)\n",
    "print('Neural Networks - Best Model:', grid_search_nn.best_estimator_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing model\n",
    "# nn = MLPClassifier(hidden_layer_sizes=, activation=, solver=, learning_rate=, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Vote of the best found models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vc = VotingClassifier([MODELS], voting = 'soft', weights = [0.85, 1, 0.85, 0.75])\n",
    "# vc = VotingClassifier([('rf', rf), ('xgb', xgb),('cat', cat), ('bag', bag)], voting = 'soft', weights = [0.861, 0.78, 0.706, 0.751])\n",
    "\n",
    "#fit and predict\n",
    "vc.fit(X_train , y_train)\n",
    "pred= vc .predict(X_test)\n",
    "pred_train = vc .predict(X_train)\n",
    "\n",
    "\n",
    "#print best model scores on test data\n",
    "print(\"Accuracy score train: {}\".format(accuracy_score(y_train ,pred_train)))\n",
    "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, pred)))\n",
    "\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "#heatmap\n",
    "fig, ax = plt.subplots(figsize=(8,5)) \n",
    "data = confusion_matrix(y_test, pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "ax = sns.heatmap(df_cm, cmap='Blues', fmt='g' ,annot=True,annot_kws={\"size\": 14})\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel (\"Actual\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "ax.set_yticklabels(ax.get_xticklabels(), rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering Research Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What are the main factors associated with pump failure or malfunction, and how do these vary across different regions of Tanzania?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which operators and/or management groups have the highest success rates in maintaining water pumps, and how do these rates vary based on factors which may make pump maintenance easier, such as water cost, pump type, or location remoteness?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What are the interactions between different features, such as water quantity and pump type, which could provide insights into the underlying causes of pump failure?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How does the age of a water pump relate to its functionality, and is there a point at which pumps become significantly more likely to break down or require replacement?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What is the most reliable machine learning method for pump failure prediction?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
